# Lewis's Argument

## Introduction

In a pair of papers from the second half of his illustrious career, David Lewis argued against a thesis he called "Desire as Belief". The papers had the somewhat unimaginative names "Desire as Belief" [@Lewis1988] and "Desire as Belief II" [@Lewis1996]. The arguments have proven to be rather perplexing. There is nothing like a consensus in the literature on how to formulate the argument, on what its strengths and weaknesses are, or even what the argument would show if it succeeded.

But let's start with a reasonably simple version of the argument. Assume Max is a rational agent, who can be accurately represented as having credence function $C$ and value function $V$. That is, Max's preferences are such that he always prefers the option with the highest expected value for $V$, given his credence function $C$. Now if you know almost anything about philosophical work on decision theory over the last 50 years, you'll know that this assumption contains an ambiguity. When we say Max optimises expected utility, are we understanding that the way that evidential decision theorists do, or the way that causal decision theorists do, or perhaps some other way?^[For good treatments of these two ideas, albeit from partisans of the causal side of the debate, see @Weyrich2012 and @Joyce1999.] Lewis says in a parenthetical paragraph that how we resolve this ambiguity isn't going to matter.^[Include reference] @Collins2015 pointedly disagrees, and I am going to adopt Collins's view wholeheartedly in what follows. But set that aside for now, and just say that Max's utility function is $V$ and credence function is $C$.

Assume also, and this really is just for simplicity, that Max's utility function is binary in the following sense. For every maximally specific possibility, it either is Good, and gets value 1, or is Bad, and gets value 0. I will relax this assumption at times, but it really helps ease the presentation if we start with this simple case.
 
Now we make the big assumption about Max. His desires correlate with his beliefs about the good. Here's how we're going to represent that. For any factual proposition $A$, we'll assume that there is another proposition $A°$, to be read as _A is good_. (And I'll come back to what I mean by saying something is a factual proposition. For now, all that matters is that I am not assuming that the operator $°$ can be applied iteratively. I don't assume that Max has attitudes towards, or even the conceptual resources to think about, a proposition we might write as $A°°$, i.e., it is good that it is good that $A$.) In the first paper, Lewis had used $Å$ rather than $A°$, but most fonts contain only a few letters with this kind of overring, so using a degree symbol after the letter is more convenient. In the second paper, Lewis calls this the halo function, which explains half the title of this book. Anyway, Max can think thoughts about these propositions $A°$. And what he thinks is that the amount that he values $A$ exactly tracks how probable he thinks it is that $A$ is good. In symbols, Max endorses:

Desire as Belief (DaB)
:    $V(A) = C(A°)$

I am going to have a lot to say about the different ways we might interpret this equation, but for now it's just an equation. Crucially, Max is stably disposed to conform to this equation. In particular, even after learning new information, Max will still satisfy this equation, for all $A$. 

Sadly for Max, and especially sadly for those philosophers who think that ideal agents should be like Max and conform to this equation, it is irrational to consistently hold onto it. The proof I'm about to give of this is not the complicated argument that Lewis gives in [-@Lewis1988], but a slightly expansive version of the argument he gives in [-@Lewis1996]. Lewis notes the argument is similar to one offered by @ArloCostaEtAl1995. My presentation draws on the presentations in @RussellHawthorne2016 and @Collins2015. As well as using $V$ and $C$ for Max's value and credence functions, I'll use subscripts for updating. That is, I'll write $V_A$ for Max's value function after he updates with the information that $A$, and $C_A$ for his credence function after he updates with the information that $A$. Whenever I use a single uppercase letter for the name of a proposition (or similar thing that Max has attitudes towards), that will be a factual proposition (in a sense of factual I'll come back to far below). 

Finally, I'll use $w$ to either denote a single 'world', or as a variable ranging over worlds. I'll say a lot more about worlds in what follows, but for now note that they are things that set the truth value of all propositions that are currently relevant. So they are more fine-grained in some senses, and less fine-grained in others, than Lewisian concreta. They are more fine-grained because we could have a pair of worlds, in this sense, that are alike in descriptive respects, but unlike in evaluative respects. I will need these worlds because I will try to model agents who are uncertain about evaluative claims, but whose actions are sensitive to their beliefs about the evaluative. They are less fine-grained because they only determine the truth values of things that are currently relevant. They are like the 'small worlds' in the sense of @Savage1954. They don't determine last night's baseball results, let alone the speed of each pitch in each of those games. Because they are small in this sense, we will assume that they are finitely many of them. This is an idealisation, but not much of one. It is rare, if not impossible, that we are interested in more than finitely many things at once. And even if one of those things could in principle take an infinity of values (because, e.g., it is a continuous function like the speed of a pitch), the difference between a continuous function and a finite approximation to it will typically be negligible. 

With that formalism on the table, I can state the four assumptions quite easily. The first is a formalisation of one of the assumptions we've already made about Max; the other three are new.

Good-Bad
:    All worlds are either GOOD or BAD. If $w$ is GOOD, then $V(w) = 1$, and otherwise $V(w) = 0$

Invariance
:    $V_A(w) = V(w)$

Additivity
:    $V(A) = \sum_w V(w)C(w | A)$

Restricted Conditionalisation
:    $C_A(B) = C(B | A)$

I'm calling the last _Restricted_ Conditionalisation because I only mean it to apply in the case where $A$ is a factual proposition. Lewis doesn't explicitly say what restriction he is putting on conditionalisation, but he does make clear in footnote 6 of [-@Lewis1996] that he doesn't need or want to endorse a general version.

Note that we really need Good-Bad to make **DaB** plausible. If we didn't have Good-Bad, then we wouldn't even have $V$ and $C$ on the same scale. But if values and probabilities are at least on the same scale, then the thesis passes a minimal threshold of plausibility. Nevertheless, it is false. It is false because it leads to some absurd independence results. In particular, the following proof shows that $A$ and $A°$ are probabilistically independent according to $C$.

-------- ----------------------------- --------------------------------------------
 $C(A°)$ $=V(A)$
         $=\sum_w V(w)C(w | A)$        (Additivity)
         $=\sum_w V_A(w)C(w | A)$      (Invariance) 
         $=\sum_w V_A(w)C_A(w)$        (Restricted Conditionalisation) 
         $=V_A(A)$                     (Additivity), applied after updating on $A$ 
         $=C_A(A°)$                    (DaB), applied after updating on $A$ 
         $=C(A° | A)$                  (Restricted COnditionalisation) 
-------- ----------------------------- --------------------------------------------

That is, Max treats $A$ and $A°$ as independent. And this is absurd. Imagine that $A$ is the proposition that Max's hero, Jean, performs a certain action. As it stands, Max is very unsure whether this would be the right thing for Jean to do. But he is sure that Jean will do the right thing. This seems like a coherent set of attitudes for Max, at least if it is coherent to be uncertain about what is best. But we've just shown that given **DaB** and these other assumptions, it is not coherent. If Max satisfies these assumptions, then the fact that Jean does something can be no evidence that it is right, no matter how much background evidence Max has that Jean is a moral role-model. That's absurd, so one of the assumptions must go.

The argument I've given here is taken more directly from @Nissan-Rozen2015-NISATR than from Lewis, though you can sort of see it as a variant on the argument Lewis gives. Lewis argues that Independence is absurd by considering what would happen if Max updated his credences with the information that $A \vee A°$. At some level, the real lesson of Lewis's arguments here, and his related arguments about conditionals [@Lewis1976b; @Lewis1986h], is that correlations involving credences are really hard to preserve across updates. And since anything you could say could in principle be learned - it's at least possible to meet an Oracle and have them tell you that $p$ for any $p$ you can say - that puts a real constraint on these correlation theses. And that's all I've done in the previous paragraph. Max has learned, via his observation of Jean's moral probity, that if Jean makes $A$ true, then $A°$ is true as well. If the correlation between $C(A°)$ and $V(A)$ holds universally, it must hold in this special case. But it doesn't, so there is something wrong with the correlation.

But I'm not sure that focussing on the person who learns $A \vee A°$ is the best way to see the problem. Lewis points out that if Max does give credence 1 to $A \vee A°$, and $A$ and $A°$ are independent, then he must given credence 1 to either $A$ or $A°$. And then he tries to argue this is absurd. But while there are, I think, three different ways to finish this argument, none of them seem quite compelling.

First, we could note that no matter how we update, assuming that after update Max's credences are a probability function, and $C(A \vee A°)=1$, we can prove[^FirstLewisProof] after update either $C(A) = 1$ or $C(A°)=1$. And we could appeal to the intuitive implausibility of that. The problem with this appeal to intuition is that it's so hard to imagine what it would be like to learn $A \vee A°$, and nothing else, that it's hard to know what such an update should intuitively be like. Unlike the story I told of Max and Jean, it's hard to see what everyday experiences would lead to learning that. And I, at least, don't have firm intuitions about how to update if Max learns that via an Oracle.

Second, we could try to argue that this learning should go via conditionalisation. That is, after learning $A \vee A°$, then Max's new credence in any proposition $X$ should be his old credence in it conditional on $A \vee A°$. And then we can prove[^SecondLewisProof] that right now Max must have an extreme credence, either 1 or 0, in either $A$ or $A°$. That is, even before meeting any Oracles or the like, Max cannot both be uncertain about whether $A$ will happen, and whether it should happen. That's really absurd. But it is easy enough for the defender of **DaB** to simply deny that updating on morally loaded propositions like $A \vee A°$ should go via conditionalisation.

Third, we could try to argue by elimination that all possible formal models for update will have problems just as bad as the problems mentioned in the last paragraph. And the problem with this is simply that it's too hard to exhaust the formal models for update, even if we impose some kind of minimal viability condition on the models. This will be a bit of a running theme of later chapters of this book.

So I don't think this particular argument will work. But I don't want to make too much of the difference. After all, my argument can just be rephrased as saying that if $A$ and $A°$ are independent, so are $\neg A$ and $A°$, and that is absurd in the case where Max learns $\neg A \vee A°$. So the similarities between the argument I'm offering and the one Lewis had already offered are greater than the differences.

[^FirstLewisProof]: Assume for reductio that $C$ is a probability function, that this function makes $A, A°$ independent, that both $C(A)$ and $C(A°)$ are less than 1, and $C(A \vee A°)=1$. Let $C(A) = x$, and $C(A°) = y$. By independence, $C(A \wedge A°) = xy$. Since $C(A) = C(A \wedge A°) + C(A \wedge \neg A°)$, it follows that $C(A \wedge \neg A°) = x - xy$. Since $C(\neg A°) = C(A \wedge \neg A°) + C(\neg A \wedge \neg A°)$, it follows that $1-y = (x - xy) + C(\neg A \wedge \neg A°)$. But $C(\neg A \wedge \neg A°) = 0$, since $C(A \vee A°) = 1$. So $1 - y = x - xy$. Since $y < 1$, we can divide both sides by $1-y$, getting $1 = x$, contradicting the assumption that $x < 1$.

[^SecondLewisProof]: Assume for reductio that $C$ is a probability function, and that $A, A°$ are indepedendent both unconditionally, and conditional on $A \vee A°$. The proof of the previous footnote implies that at least one of $C(A | A \vee A°)$ and $C(A° | A \vee A°)$ is 1. The situation is completely symmetric, so without loss of generality assume it is $C(A | A \vee A°) = 1$. From this it follows that $C(\neg A \wedge A° | A \vee A°) = 0$, so $C(\neg A \wedge A°) = 0$. So $C(A°) = C(A \wedge A°) + C(\neg A \wedge A°) = C(A \wedge A°)$. But by the independence of $A, A°$, we also have $C(A \wedge A°) = C(A)C(A°)$. Putting these two together, it follows that $C(A°) = C(A)C(A°)$, contradicting the assumption that $C(A) < 1$.

## Four Versions of Max

So it's bad to be just like Max. But what follows from that philosophically? Lewis says that the argument raises a problem for "anti-Humean" views. But this obscures more than it clarifies, since there are a lot of views that Lewis took to be anti-Humean. I find it helpful to think through four ways we might understand both the halo operator, and Max, that generate the potential argument. The first three ways take $A°$ to mean _A is good_. The fourth will be a bit more complex.

Max-1 does not have desires at all. Or, if he has them, they play no role in his action. So here's how a typical action of Max's proceeds. He walks to the bowl to get an orange. He doesn't do this because he wants an orange, and believes they are in the bowl. Rather, he believes that there are oranges in the bowl, and believes that it would be good to have an orange, and those two beliefs completely explain his walking to the bowl. We can model Max using the familiar $C, V$ functions from decision theory, but this model is misleading; $V$ is really measuring a second part of Max's credal state.

Max-2 has a more familiar belief-desire psychology. He walks to the bowl because of a desire for oranges, and a belief that that's where the oranges are. But in Max-2 there is a metaphysically necessary connection between desires and the good. It just isn't possible for him to have a desire for an orange without a belief that oranges are good, or vice versa. Now it is less misleading to use a standard decision-theoretic model on Max, since he really does have beliefs (represented by $C$), and desires (represented by $V$). But these two are prevented from freely recombining; some combinations of $C$ and $V$ are impossible for Max.

Max-3 is like Max-2, but without the restriction on recombination. What's distinctive about Max-3 is that he is governed by a norm connecting desires with beliefs about the good. Sometimes he desires that which he does not believe to be good, and sometimes he believes that to be good which he does not desire. But these are failings; he shouldn't do that. I could subdivide this case further, depending on how to disambiguate this 'should', but that's unnecessary for now.

Max-4 takes a bit longer to state. No longer read $A°$ as _A is good_. Instead, read it as saying _A is X_, where _X_ is the feature that actually makes actions good. So if all there is to morality is conformity to the categorical imperative, then $A°$ means _A conforms to the categorical imperative_. Now Max-4 is like Max-3. Metaphysically there is nothing impossible about $C$ and $V$ floating free from each other. But if Max is being good, there should be a connection. In particular, Max should only want to do, i.e., value as good, actions that conform to the categorical imperative. That is, Max should value $A$ only if he believes that $A°$.

Now consider four philosophers, who I'll name Athena-1, 2, 3 and 4. Each Athena thinks the corresponding version of Max is a good model for real humans. So Athena-1 thinks that humans are (at least often) like Max-1; Athena-2 thinks they are like Max-2, and so on. And then we can think that the formal argument is meant to show that each of the Athenas is mistaken.

And this certainly feels like it would be a victory for any number of anti-Humean theses. Athena-1 thinks denies the Humean dictum that reasons are slaves of the passions. Rather, she thinks that (at least when things are going well), reasons are in the driver's seat. And Athena-2 seems to deny the Humean dictum that there are no necessary connections between distinct existences. She thinks that there is a metaphysical connection between the beliefs of (at least some) ordinary humans and their desires. 

In Lewis's two papers the relationship between his argument against what he calls anti-Humean moral psychology (views that deny that reason is the slave of the passions), and what he calls anti-Humean modal metaphysics (views that accept metaphysical connections between distinct existences). Thinking through the possible ways to interpret Max suggests really the argument is an argument against both of these. I'm going to set both this suggestion, and more careful Lewis exegsis aside however, and think a bit more about Athena-3 and Athena-4.^[Note to self: If I come back to a Lewis exegesis chapter, flag it here.]

Athena-3 allows that people can have desires that come apart from their beliefs about the good. She just thinks that this is a failing. Simplifying only a little, she thinks that hypocricy is a vice. She thinks it is bad to do that which is bad by your own lights. Or, at least, she holds a slightly more complicated probabilistic version of that principle. 

On the face of it, it's hard to see how that is anti-Humean. If Athena-3 thinks that the direction of explanation goes from beliefs to values, then she's getting close to denying that reason ought be the slave of the passions. But she need not endorse this order of explanation in virtue of accepting the correlation. She may think that passions, i.e., desires, should be driving the ship, and have a moral epistemology where beliefs should follow feelings of value. Or, returning to the point I flagged about the ambiguity of 'should', she may think that not satisfying this correlation is a very specific kind of vice, not one that is always most important. So she may think that all things considered, reason should be the slave of the passions, but from the perspective of not being a hypocrite, reason and passion should correlate. And as long as we think norms can exist while being over-ridden, this position looks consistent with any kind of Humean moral psychology.

Athena-4 doesn't even think anything that substantive. She just thinks that there is some feature in virtue of which things are valuable, and it is a failing to not value things one takes to have that feature. Lewis sometimes writes that the argument is related to debates about "objective ethics", but I'm not assuming Athena-4 believes in any such thing. Perhaps she does, but perhaps she thinks that things are valuable in virtue of folks around here valuing them. She's mostly just committed to the idea that it is a failing to not value the valuable. And if that makes one anti-Humean, it's not clear why we'd want to be Humeans.

To be a bit more careful, Athena-4 is making a slightly more substantive claim than this. Recall that I've set up the argument so far using **Good-Bad** as a simplifying assumption, and that eventually that will have to be dropped. It will turn out when we drop that assumption in virtue of something more plausible, Athena-4 will have to make some non-trivial assumptions about the topolgy of value. In particular, she will have to think that values have something like the structure of (some subset of) the real numbers. To put in terms from present debates, she'll have to believe in a moral theory that can be "consequentialised". That's not to say she has to be a consequentialism in any ordinary sense, just that her theory has to be translatable into consequentialist language. Ever since @Moore1903 there has been a view in philosophy that this is a trivial requirement, so Athena-4 really isn't committing to anything here. I'm more sympathetic to the argument that Campbell @Brown2011-BROCT makes that not all theories survive such translation. But this is a really small side point. It can't be any part of Humeanism in meta-ethics or metaphysics that our moral theory falls on one or other side of this divide. If Lewis's argument shows that Athena-4 is mistaken, it proves way more than that Humeans win one or other debate.

And this is a big reason for being very suspicious of the argument so far. It simply proves too much. That doesn't tell us where or how the argument fails, but it gives us very good reason to think it must indeed fail. 

Goes with four versions of Athena

1. Guise of the good
2. Necessary connection
3. Enkrasia
4. Really really broad

Note that in 1988 paper Lewis seems to appreciate broadness, but just backs off for some unclear reason.

## Plan for Book

* Write at the end
