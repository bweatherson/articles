---
title: "Knowledge: A Human Interest Story"
author: "Brian Weatherson"
format:
  revealjs:
      template-partials:
        - title-slide.html
      slide-number: c/t
      menu: true
      highlight-style: github-dark
      theme: teodt.scss
      logo: UM.svg
editor: source
---

# Links

:::{.columns}
:::{.column width="50%"}
![Slides - https://brian.weatherson.org/gem/](gem.png){width="80%"}
:::

:::{.column width="50%"}
![Book - https://brian.weatherson.org/kahis/](kahis.png){width="80%"}
:::
:::

---

![Opening of _Knowledge: A Human Interest Story_](kahis-title.png){width="70%"}

# Big Claim

Knowledge is sensitive to interests.

Two people alike in all other relevant respects, but with different interests, have different knowledge.

# Schematic Argument

1. One isn't taking an unacceptable epistemic risk by starting an inquiry with what one knows.
2. For almost anything we purport to know, there are some inquiries where it would be unacceptably risky to start with that, purported, knowledge.
3. We know a lot.
4. Therefore, what we know must vary between inquiries.

# Example

Let *p* be the following proposition:

- Frankfurt am Main airport is the busiest airport in Germany; i.e., it has the most passengers per year.

We all know that *p* is true.

---

![https://en.wikipedia.org/wiki/List_of_the_busiest_airports_in_Europe](airports.png){width="70%"}

# An Old Argument

Ansgar is offered the following bet, take it or leave it.

- If he takes the bet and *p* is true, a child somewhere gets a moment's happiness, like from a game of peek-a-book.
- If he takes the bet and *p* is false, all of humanity is cast into The Bad Place for all eternity.
- If he declines the bet, nothing happens.

# An Old Argument

1. Ansgar should decline the bet.
2. If offered a bet, and Ansgar knows taking the bet will be better than declining the bet, Ansgar should take the bet.
3. If Ansgar knows that *p*, Ansgar knows taking the bet will be better than declining the bet.
4. Therefore, Ansgar does not know that *p*.

# Continuing the Argument

5. Someone with Ansgar's evidence who is not facing, or thinking about, bets like this, knows that *p*.
6. Therefore, what one knows depends on what kinds of bets one is facing, or thinking about.

# A Mistaken Inference

Some say this kind of case shows that knowledge is particularly sensitive to the **practical** interests of the (would-be) knower.

I reject this for two reasons.

1. I'm not sure how much this case *shows*. We'll come back to this.
2. The case need not be practical.

# A Theoretical Version

- Imagine Ansgar isn't actually facing this bet.
- But for whatever reason, perhaps because he's a philosopher, he's thinking about what he would do if he were offered it.
- In that purely hypothetical inquiry, he should still decline, so he still doesn't know.

# Another Mistake

The other conclusion that's sometimes drawn from cases like this one is that knowledge goes away in **high stakes** cases.

This is not right for two reasons.

1. It turns out to be very hard to articulate what the stakes are in cases where there are more than two options.
2. We can get similar results in relatively low stakes cases.

# Red-Blue Game

Willian is playing a game show on TV. One of the games has the following rules.

- Two sentences will be written on the board.
- One will be red, the other will be blue.
- The player has to choose a sentence, red or blue, and say whether it is true or false.
- If they say the correct truth value, they win €50. If they say the incorrect truth value, they win nothing.

---

- [Two plus two equals four.]{style="color:red; font-size:200%"}

- [Frankfurt am Main airport is the busiest airport in Germany.]{style="color:blue; font-size:200%"}

# Another Argument

1. It is irrational for Willian to play Blue-True; the only rational play is Red-True. Any other play is silly (the false options) or needlessly risky (Blue-True).
2. If there is an option that Willian knows gets the maximum possible payout, it is rationally permissible to take that option.
3. If Ansgar knows that *p*, Ansgar knows that Blue-True will get the maximum possible payout.
4. Therefore, Ansgar does not know that *p*.

# Two Observations

- This argument does not rely on extreme cases involving crisis situations, where intuitions might easily go astray.
- If this argument works, the argument for interest-relativity need not involve **high** stakes. 

# Odds and Stakes

It's the odds, not the stakes that matter.

Choosing to play Blue-True over Red-True is a risk with no upside, so it's an infinitely long odds bet.

# Overview

- So far I've set out the main argument for the interest-relative view.
- Next I want to go over some alternative positions, ones that offer responses to the argument.
- I'll close by placing some of these views, and this interest-relative view, in historical context.

# Four Families of Views

I'll describe these more on later slides.

1. Interest-relative
2. Sceptical
3. Epistemic
4. Orthodox

# Interest-Relative

This is the view I support.

Ansgar and Willian lose knowledge when they are offered these bets.

# Sceptical

The sceptic agrees with the conclusion of the argument that Ansgar and Willian don't know that *p*.

They reject interest-relativity because they say that even in normal situations, they don't have knowledge either.

I think this view is implausible, but I'll put off arguments for it until the historical section of the talk.

# Epistemicist

By epistemicist, I mean here the combination of these three views:

1. Knowledge suffices for rational action;
2. We know a lot;
3. Knowledge is invariant with changes of interests.

This view is committed to saying that Ansgar and Willian are rational in taking the bet, and playing Blue-True.

# Epistemicist

That's not particularly intuitive, but the best epistemicists have an interesting story about why intuition disagrees with their position here.

The intuitions are correct intuitions about **actors**, confused for false claims about **actions**.

# Epistemicist

So here's the key thought.

- Ansgar and Willian, if they take the bet and play Blue-True, manifest practical (and maybe moral) **vices**.
- These are character level evaluations.
- Surprisingly, they manifest these vices while performing rational (and moral) **actions**.

# Actions and Actors

I actually think this is a not implausible thing to say about Ansgar.

Perhaps maximising expected value, even when the stakes are so high, is a sign of bad character.

But I think it's not a very plausible thing to say about Willian. That's the better case for interest-relativity.

# Orthodoxy

The more common view, at least in contemporary epistemology, is that we have to give up natural connections between knowledge and action.

# Orthodoxy

- It is not rational for Ansgar or Willian to take these risky bets.
- Ordinary people (who have read Wikipedia) know that *p*.
- Knowledge is only sensitive to factors connected to truth, or evidence, or something of the sort.
- Therefore, doing something that one knows will be for the best is sometimes irrational.

# Orthodoxy

In the book I go over several ways to make that last bullet point sound even more implausible.

But I don't think many people think it's naturally where you'd want to end up.

Rather, they think that having knowledge be interest-sensitive is so absurd that it's worth dealing with this cost.

# Interests and Intuitions

In the book I have two broad kinds of move to this last point.

1. Interests are an issue for everyone.
2. Connecting knowledge and interests fits better with the history of epistemology.

# Interests and Backgrounds

- It's very plausible that knowledge has a reliability constraint.
- Reliability is always relative to a reference class.
- Which things are in the reference class is plausibly interest-relative.
- A method that goes wrong in environment E is unreliable if E is someplace I'm likely to find myself.
- That last clause is interest-relative.

# Interests and History

A quick tour through four stops:

1. Nyāya
2. Late academic scepticism
3. Medieval jurisprudence
4. Early modern science

# Nyāya

Here's an anti-sceptical argument you can find in the Nyāya philosophers.

1. Some actions are rational and some are foolish.
2. A necessary condition on an action being rational is that it is grounded in knowledge.
3. So some people know some things, contra the sceptic.

# Arguments

- You might be thinking this is a somewhat question-begging argument.
- And if so, you might be familiar with how the next few moves typically play out.
- But rather than going down that rabbit hole, I want to think of this as a challenge to the sceptic.

# The Challenge

If scepticism is true, what is the difference between rational and irrational action?

# Philo

::: columns
::: {.column width="40%"}

![](philo.png){width="80%"}
:::

::: {.column width="60%"}

This is a challenge that sceptics have taken up.

Philo, one of the last sceptical heads of The Academy, worried a lot about it.

:::
:::

# Philo

::: columns
::: {.column width="40%"}

![](philo.png){width="80%"}
:::

::: {.column width="60%"}

His solution was to say that while we cannot know things, we can rationally accept some things, and rational action is based on rational acceptance.

:::
:::

# Philo

Now we could talk about how, and whether, that is meant to work with scepticism.

But I want to note one other thing about Philo's view.

He thought that how much evidence you needed for rational acceptance was dependent on how much was at stake.

He had an interest-relative view of rational accepance.

# Back to the Present

A very simple way of getting an interest-relative view would be to start with Philo and add two things.

1. What he called acceptance is really belief.
2. Knowledge is the norm of belief.

That's very close to my view.

# Medieval and Modern

::: columns
::: {.column width="50%"}
![Robert Pasnau](bob.jpg){width="60%"}
:::

::: {.column width="50%"}
![After Certainty](after_certainty.jpg){width="62%"}
:::
:::

# Moral Certainty

Leaping ahead 1500 years, medieval ethicists were worried about a somewhat practical problem.

Imagine that a judge is faced with a murder defendent, and the evidence of guilt is overwhelming.

The judge finds the defendent guilty, and the defendent is executed. But, sadly, he was innocent.

Is the judge a murderer? Has the judge sinned?

# Moral Certainty

The response was to develop a concept of _moral certainty_.

The judge has not sinned if given the evidence, it is morally certain that the defendent is guilty.

This isn't meant to be a triviality. In high stakes cases, it takes much more to be morally certain than in low stakes cases.

# Moral Certainty

This isn't an interest relative account of **knowledge**.

The whole point is that we're thinking of standards for beliefs that turn out to be false.

But it's very close.

# Interests and Standards

What's common to the last two cases is this.

- When philosophers look for epistemic standards that are meaningful, but not maximal, they often make them interest-relative.
- Hypothesis: It's very hard to find non-maximal, interest-invariant, standards in the epistemology literature before early modern times.

# Early Moderns

I'll end with a conjecture.

Contemporary orthodoxy in epistemology is largely about finding standards that satisfy three requirements.

1. Philosophically interesting.
2. Non-maximal.
3. Interest-invariant.

# A Conjecture

It's only with the rise of scientific journals that the search for a standard meeting these three conditions becomes important.

# John Wilkins

:::{.columns}
:::{.column width="40%"}
![Bishop John Wilkins](Bp_John_Wilkins.jpg){width="80%"}
:::

:::{.column width="60%"}
Pasnau suggests that in the story about how 1 and 2 became important, we should give special attention to John Wilkins.
:::
:::

# John Wilkins

:::{.columns}
:::{.column width="40%"}
![Bishop John Wilkins](Bp_John_Wilkins.jpg){width="80%"}
:::

:::{.column width="60%"}
Pasnau suggests that in the story about how 1 and 2 became important, we should give special attention to John Wilkins.
:::
:::

# Journals

It's easy to come up with circumstances where we have philosophical uses for non-maximal standards.

We're trying to judge whether people are taking rational precautions about lions (Philo), or whether judges are being moral (medievals).

In both cases, having standards be sensitive to the practical situation seems sensible.

# Journals

When could we want a standard that is non-maximal, but where the particular practical situation is irrelevant?

Answer: When we're publishing a scientific journal.

# Journal

Three constraints on publishing a journal.

1. We want the fact that we've published something to be a meaningful mark of quality.
2. We want to be able to publish, so we can't have Cartesian certainty.
3. We don't know who is going to read the journal, or what use they'll put it to.

# Journals

My conjecture, and it is just a conjecture, is that this is the real founding of epistemology as we know it today.

It's the task of coming up with standards like _Is this acceptable to publish in a scientific journal?_.

That's an interesting question, but it's not the only question we might be interested in.

# Back to Interests

In general, I think Philo and the medievals were on the right track.

Knowledge is to be used, and the standards for knowledge should be sensitive to what it is used for.

# Back to Interests

That's fundamentally why we should have an interest-relative theory of knowledge.

And hopefully through this book I'll convince some people of that!

:::{.columns}
:::{.column width="50%"}
![Link to Open Book Publishing](openbook.png){width="60%"}
:::

:::{.column width="50%"}
![Link to book manuscript](kahis.png){width="60%"}
:::
:::



  