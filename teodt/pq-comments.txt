I think the main weakness of the paper is that the observations the author makes are mostly already pretty widely appreciated in the literature, and the additional lessons the author tries to draw are too undercooked. More detailed thoughts below:
-The author begins by going through reasons why decision theory is not best understood as telling us which actions produce the best outcomes. As the author notes, that is not controversial.
-They go on to discuss whether a decision theory tells us what the best advice is. I agree with the author that this is also not what a decision theory does. I think decision theorists in general would agree as well. So to some extent I worry the author is batting at ghosts here, and I'm not sure how important the advice view is as a foil. But in any case I think the author's explanation why the advice view is wrong isn't quite right. In the author's simple Betting case, they take for granted that the best advice is to Pass. But this is not at all obvious. The author's reasoning for why Passing is the best advice seems to be that the agent cannot follow the advice "bet on the winner" since they're not in a position to know who the winner is. This is true. But that's not the only possible alternative advice. Suppose Home is in fact the winner. One piece of advice one could give the agent is "bet on Home". The agent can bet on Home, since they know who Home is. And betting on Home would be much better for the agent than passing. So arguably, "Bet on Home" is better advice than "Pass". Of course, to know that "Bet on Home" is better advice, one has to use information that the agent lacks. But it is not in general a feature of advice that one can only advise on the basis of information the agent one is advising already has. So there seems to have to be some additional condition on the kind of advice we would be interested in to rule out this as an appropriate bit of advice. Perhaps we need to be interested in advice which only uses knowledge the agent has. Perhaps it is advice about something more general than an individual action, like a general algorithm for solving a range of problems the details of which might be unpredictable. In any case, I think things quickly get messy in a way the author doesn't appreciate.
-The author's positive view is that decision theories "are answers to a question about what an ideal decider would do. The 'ideal' here is like the 'ideal' in a scientific idealisation, not the ideal in something like an ideal advisor moral theory. That is, the ideal decider is an idealisation in the sense of being simple, not in the sense of being perfect. The ideal decision maker is ideal in the same way that the point-masses in the ideal gas model are ideal; they are (relatively) simple to work with. The main opponent I have in mind is someone who says that in some sense decision theory tells us what decisions we should make."
The idealization the author has in mind is something like perfect computational ability. On this view, then, a decision theory is a prediction about what a version of the agent with perfect computational ability would do. Notice that this is a purely non-normative question (and indeed, the author is explicit that the idealization is not a normative one). But I think this is untenable. Consider the disagreement between causalists and evidentialists about newcomb's problem. On the author's interpretation, read literally, the causalists are predicting that agents which have perfect computational ability would choose two boxes, and evidentialists are predicting that agents which have perfect computational ability would choose one box. But this is obviously not the disagreement. For one, if we found an agent with perfect computational ability, and gave them newcomb's problem, their behavior would not tell us who is right. And in fact, we already know in advance that there are some possible agents who, with perfect computational ability, would choose one box, and other agents who, with perfect computational ability, would choose two boxes. The question isn't about what a non-normatively idealized agent would choose, but about what a practically rational agent (perhaps also non-normatively idealized in some ways) would choose.
Also notable is that even the non-normatively characterized part of the idealization - perfect computational ability - is arguably there because perfect computational ability is part of full epistemic rationality - people are rationally deficient to the extent they fail to exhibit it.
Together this means that once we fix the author's view to make it plausible (and accept a common view about epistemic rationality that the author does not anywhere challenge), we are left with the view that decision theories are just views about what an ideally practically and epistemically rational person would do. And I think that's more or less what decision theorists typically think. So it's hard for me to see what is really new in the author's picture here.
Perhaps even if the view itself isn't particularly novel, there could be new lessons drawn from it which are worth publishing. But I think the author's upshots are very cursory. They suggest that there is room for non-ideal theory, which looks at what agents should do in light of their cognitive limitations. But this is not new -Julia Staffel and many others have done work on bounded rationality.

They suggest that one-boxing and two-boxing might be reconciled as appropriate for the ideal/non-ideal levels. But this is not well-developed and the author themselves doesn't even seem to find this very promising.