---
title: "Humberstone on Possibility Frames"
abstract: |
  Insert abstract here
date: Feb 11 2026
draft: false
execute:
  echo: false
  warning: false
author:
  - name: Brian Weatherson 
    url: http://brian.weatherson.org
    affiliation: University of Michigan
    affiliation_url: https://umich.edu
    orcid_id: 0000-0002-0830-141X
categories:
  - logic
  - metaphysics
bibliography: 
 - /Users/weath/Documents/quarto-articles/brian-quarto.bib
format:
  html:
    fig-format: png
    fig-width: 10
    fig-height: 7
    embed-resources: true
  pdf: 
    documentclass: article
    classoption: twoside
    keep-tex: true
    geometry:
      - paperheight=10in,
      - paperwidth=7in,
      - top=1in
      - bottom=1in
      - inner=0.8in
      - outer=0.8in
      - headsep=0.25in
      - headheight=1in
      - footskip=0.35in
    pdf-engine: xelatex
    mathfont: EB Garamond Math
    mainfont: EB Garamond Math
    sansfont: EB Garamond SemiBold
    mainfontoptions: 
      - ItalicFont=EB Garamond Italic
      - BoldFont=EB Garamond SemiBold
    fontsize: 10.5pt
    linkcolor: blue
    urlcolor: blue
    colorlinks: true
    linestretch: 1
    link-citations: true
    link-bibliography: false
    output-file: "Humberstone on Possibility Frames"
    include-in-header:
      - maketitle.tex
      - body-style.tex
      - doi-setup-aggressive.tex
      - text: |
          \newcommand{\nmodels}{\mathrel{\ooalign{$\models$\cr\raisebox{-0.001ex}{\hss$\mkern-1mu/\hss$}\cr}}}
          \newcommand{\llbracket}{[\![}
          \newcommand{\rrbracket}{]\!]}
          \setlength\heavyrulewidth{0ex}
          \setlength\lightrulewidth{0ex}
          \usepackage[lines=2]{lettrine}
          \cehead{Draft of February 11, 2026}
nocite: |
  @Humberstone1981a
---

In his 1981 paper, "From Worlds to Possibilities", Lloyd Humberstone shows a way to do modal logic without the apparatus of possible worlds. Instead of worlds he uses _possibilities_, which may, unlike worlds, be incomplete. The non-modal parts of the view are discussed again in section 6.44 of _The Connectives_, though the differences between the view there and the 1981 view are largely presentational. In this paper I'll set out this _possibility frame_ approach to modal logic, make some notes about its logic, and end with a survey of the many possible applications it has.

Mathematically, possibilities are just points in a model, just like possible worlds are points in different kinds of models. But it helps to have a mental picture of what kind of thing they are. In "From Worlds to Possibilities", Humberstone notes that one picture you could have is that they are sets of possible worlds. This isn't a terrible picture, but it's not perfect for a couple of reasons. For one thing, as Humberstone notes, part of the point of developing possibilities is to do without the machinery of possible worlds. Understanding possibilities as sets of possible worlds wouldn't help with that project. For another, as Wesley @Holliday2025 [271-2] notes, the natural way to generate modal accessibility relations on sets of worlds from accessibility on the worlds themselves doesn't always work the way Humberstone wants accessibility to work. So let's start with a different picture.

Possibilities, as I'll think of them, are _stories_. To make things concrete, let's focus on a particular story: _A Study in Scarlet_ (@ConanDoyle1995), the story where Sherlock Holmes was introduced. That story settles some questions, both explicitly, e.g., that Holmes is a detective, and implicitly, e.g., that Holmes has never set foot on the moon. But it leaves several other questions open, e.g., how many (first) cousins Holmes has. It's not that _A Study in Scarlet_ is a story. It has proper parts which are stories. The first chapter is a story, one which tells of the first meeting between Holmes and Watson. And arguably it is a proper part of larger story, made up of all of Conan Doyle's stories of Holmes and Watson. When a story $x$ is a proper part of story $y$, what that means is that everything settled in $x$ is still true in $y$, and more things besides are settled. When this happens, we'll call $y$ a proper _refinement_ of $x$. For most purposes it will be more convenient to use the more general notion of _refinement_, where each story counts as an improper refinement of itself.

Following Humberstone, I'll write $x \leqslant y$ to mean that $y$ is a refinement of $x$. As he notes, this notation can be confusing if one things of $x$ and $y$ as sets, because in that case the refinement will typically be _smaller_.^[@Holliday2025 writes $y \sqsubseteq x$ when $y$ is a refinement of $x$, mirroring this way of thinking about possibilities.] But if we think of possibilities as stories, the notation becomes more intuitive. We have $x \leqslant y$ when $y$ is created by adding new content to $x$. Keeping with this theme, I'll typically model stories not as worlds, but as finite sequences. (In the main example in @sec-proof, they will be sequences of 0s and 1s.) In these models, $x \leqslant y$ means that $x$ is an initial segment of $y$.

# The Formal Structure {#sec-formal}

## The Basic Language {-}

To start with, assume we're working in a simple language that just has a countable set $\mathcal{P}$ countable infinity of propositional variables, and three connectives: $\neg$, $\wedge$ and $\vee$. We have a set of possibilities $W$, and a transitive refinement relation $\geqslant$ on them. The following rules show how to build what I'll call a _Humberstone possibility model_ on $\langle W, \leqslant \rangle$. (I'll call this a _possibility frame_ in most contexts, but a _Humberstone frame_ when I'm comparing it to similar structures, especially in the context of discussing @Holliday2025.)

A Humberstone possibility model $\mathcal{M}$ is a triple $\langle W, \leqslant, V \rangle$, where $V$ is a function from $\mathcal{P}$ to $W$, intuitively saying where each atomic proposition is true, satisfying these two constraints:

- For all $x$, if $x \in V(p)$ and $y \geqslant x$, then $y \in V(p)$. Intuitively, truth for atomics is **persistent** across refinements.
- For all $x$, if $\forall y \geqslant x \exists z \geqslant y: z \in V(p)$, then $x \in V(p)$. This is what @Humberstone2011 [900] calls **refinability**, and it means that $p$ only fails to be true at $x$ if there is some refinement of $x$ where it is settled as being untrue.

Given these constraints, Humberstone suggests the following theory of truth at a possibility for all sentences in this language. (We'll treat $\rightarrow$ as a defined connective, with $A \rightarrow B =_{df} A \vee \neg B$.)

\begin{align*}
[\text{Vbls}] \quad & \mathcal{M} \models_x p_i \text{ iff } x \in V(p_i); \\
[\neg] \quad & \mathcal{M} \models_x \neg A \text{ iff } \forall y \geqslant x, \, \mathcal{M} \nmodels_y  A; \\
[\wedge] \quad & \mathcal{M} \models_x A \wedge B \text{ iff } \mathcal{M} \models_x A \text{ and } \mathcal{M} \models_x B; \\
[\vee] \quad & \mathcal{M} \models_x A \vee B \text{ iff } \forall y \geqslant x \, \exists z \geqslant y \, : \, \mathcal{M} \models_z A \text{ or } \mathcal{M} \models_z B.
\end{align*}

Given these definitions, it's possible to prove three things. First, every sentence in the language is persistent. If $\mathcal{M} \models_x A$ and $x \leqslant y$, then $\mathcal{M} \models_x A$. For any sentence, truth is always preserved when moving to a refinement. Second, refinability holds for all sentences in the language. This is, as Humberstone notes, easier to state using this definition of $\neg$. It now becomes the claim, for arbitrary $A$, that if $\mathcal{M} \nmodels_x A$, there is some refinement $y$ of $x$ such that $\mathcal{M} \models_y \neg A$. Third, for any set of sentences $\Gamma$ and sentence $A$, the truth at a point of all sentences in $\Gamma$ guarantees the truth of $A$ iff the sequent $\Gamma$ entails $A$ in classical propositional logic. 

In this paper, I'm going to discuss three extensions of this language. I'll introduce them in reverse order of how much they are discussed in Humberstone, starting with one he does not discuss at all: infinitary disjunction.

## Infinitary Disjunction {-}

We'll add to the language a new symbol $\bigvee$, which forms a new sentence out of any countable set of sentences not containing $\bigvee$. Intuitively, it is true when one of the sentences in the set is true. More formally, its definition of truth at a possibility is:

\begin{align*}
[\bigvee] \quad & \mathcal{M} \models_x \bigvee ({A_1, A_2, \dots})  \text{ iff } \forall y \geqslant x \, \exists z \geqslant y \, : \,\text{ for some } i \, \mathcal{M} \models_z A_i.
\end{align*}

Again, it's fairly simple to show that this addition to the language will preserve persistence and refinability. But while this is simple, it is significant, because things could easily have been otherwise.

## Quantifiers {-}

The second extension will be to add quantifiers, following a suggestion in @Humberstone1981a [xxxx]. Assume, as usual, that the language has a stock of names $c_1, \dots$, and for each $n$, a stock of $n$-place predicates $F^n_1, F^n_2, \dots$. A _first-order (Humberstone) possibility model_ is a structure $\langle W, \leqslant, D, V \rangle$, where $D$ assigns a non-empty domain of objects to each point, and $V$ interprets the non-logical vocabulary. More precisely:

- $D$ is a function assigning to each $x \in W$ a non-empty set $D(x)$, the **domain** at $x$.
- $V$ assigns to each name $c_i$ and each $x \in W$ either a designated element $V(c_i, x) \in D(x)$, or is undefined at $x$.
- $V$ assigns to each $n$-place predicate $F^n_j$ and each $x \in W$ a set $V(F^n_j, x) \subseteq D(x)^n$, the **extension** of $F^n_j$ at $x$.

These must satisfy the following constraints:

Domain monotonicity
:    If $x \leqslant y$, then $D(x) \subseteq D(y)$.

Name coverage
:    For each name $c_i$ and each $x \in W$, there exists some $y \geqslant x$ such that $V(c_i, y)$ is defined.

Persistence for names
:    If $V(c_i, x)$ is defined and $x \leqslant y$, then $V(c_i, y)$ is defined and $V(c_i, y) = V(c_i, x)$.

Persistence for predicate extensions
:    If $\langle o_1, \dots, o_n \rangle \in V(F^n_j, x)$ and $x \leqslant y$, then $\langle o_1, \dots, o_n \rangle \in V(F^n_j, y)$.

Refinability for predicate extensions
:    If $\langle o_1, \dots, o_n \rangle \notin V(F^n_j, x)$, then there exists some $y \geqslant x$ such that for all $z \geqslant y$, $\langle o_1, \dots, o_n \rangle \notin V(F^n_j, z)$.

Given a model and a variable assignment $g$ mapping variables to objects, truth at a point is defined as follows. Write $g[v/o]$ for the assignment that maps variable $v$ to object $o$ and otherwise agrees with $g$. For a term $t$, write $\llbracket t \rrbracket^{g,x}$ for the denotation of $t$ under $g$ at $x$: for a variable $v$ this is $g(v)$, and for a name $c_i$ this is $V(c_i, x)$ when defined, and undefined otherwise.

\begin{align*}
[=] \quad & \mathcal{M}, g \models_x t_1 = t_2 \text{ iff } \forall y \geqslant x \, \exists z \geqslant y : \llbracket t_1 \rrbracket^{g,z} \text{ and } \llbracket t_2 \rrbracket^{g,z} \text{ are both defined and equal}; \\
[F^n] \quad & \mathcal{M}, g \models_x F^n_j(t_1, \dots, t_n) \text{ iff } \forall y \geqslant x \, \exists z \geqslant y : \langle \llbracket t_1 \rrbracket^{g,z}, \dots, \llbracket t_n \rrbracket^{g,z} \rangle \in V(F^n_j, z); \\
[\forall] \quad & \mathcal{M}, g \models_x \forall v \, A \text{ iff } \forall y \geqslant x \, \forall o \in D(y) : \mathcal{M}, g[v/o] \models_y A; \\
[\exists] \quad & \mathcal{M}, g \models_x \exists v \, A \text{ iff } \forall y \geqslant x \, \exists z \geqslant y \, \exists o \in D(z) : \mathcal{M}, g[v/o] \models_z A.
\end{align*}

The Boolean connectives are handled exactly as in the propositional case.

The $\forall\exists$ pattern in the atomic clauses is necessary to ensure that persistence and refinability hold for all sentences, including atomic ones. Consider $c_i = c_i$: if a name has no denotation at $x$ but acquires one at some refinement, then a simple "check the denotation at $x$" condition would leave $c_i = c_i$ neither true nor false at $x$, and no refinement of $x$ could settle it as false either, violating refinability. The $\forall\exists$ condition handles this correctly: $c_i = c_i$ is true at $x$ whenever $c_i$ is covered at $x$ (i.e., every refinement has a further refinement where $c_i$ gets a referent), since once $c_i$ gets a referent $o$, persistence of names ensures $o = o$ at all further refinements.

The atomic clauses simplify when names are fully defined. If $t_1$ and $t_2$ are variables, or names that already have denotations at $x$, then by persistence of names and predicate extensions the $\forall\exists$ quantifier prefix collapses: $\mathcal{M}, g \models_x t_1 = t_2$ iff $\llbracket t_1 \rrbracket^{g,x} = \llbracket t_2 \rrbracket^{g,x}$, and $\mathcal{M}, g \models_x F^n_j(t_1, \dots, t_n)$ iff $\langle \llbracket t_1 \rrbracket^{g,x}, \dots, \llbracket t_n \rrbracket^{g,x} \rangle \in V(F^n_j, x)$. The more complex clauses above are needed only to handle the case where some name occurring in the formula lacks a denotation at $x$ but is guaranteed to acquire one.

This is a possibilist treatment of the universal quantifier, in contrast to the actualist quantifiers discussed in @HarrisonTrainor2019. I'll return in @sec-quant to the reasons we are best off using possibilist quantifiers, and the difficulties this raises for talking about just what's true in a possibility.

## Modal Operators {-}

The third extension will be the introduction of modal operators. Here I'll follow @Humberstone1981a very closely, save just that I'll have a plurality of modal operators rather than just one. So I'll use these structures to define (as @Holliday2025 does) multi-modal logics. But I'll follow Humberstone, and not Holliday, in defining modal operators in terms of accessibility relations $R_i$ satisfying these three conditions^[I'm using the names for these that Holliday uses, which are more evocative than Humberstone's original names.]:

**UpR**:
:    If $x \leqslant x'$ and $x' R_i y$, then $x R_i y$.

**RDown**:
:    If $x R_i y$ and $y \leqslant y'$, then $x R_i y'$.

**RRef++**:
:    If $x R_i y$, then there exists $x' \geqslant x$ such that for all $x'' \geqslant x'$, $x'' R_i y$.

**UpR** says that if a refinement of $x$ can access $y$, then $x$ itself can already access $y$: accessibility is not something that can be gained by adding detail to the source. **RDown** is a converse of this; it says that accessibility cannot be gained by adding detail to the target. **RRef++** says that if $x$ can access $y$, there is some refinement $x'$ of $x$ where it is settled that $x'$ can access *y*. This last access can't be overturned by further refinement of $x'$.

Given these constraints, the truth conditions for the box operator is:

\begin{align*}
[\Box_i] \quad & \mathcal{M} \models_x \Box_i A \text{ iff } \forall y \, (x R_i y \Rightarrow \mathcal{M} \models_y A); \\
\end{align*}

This should be familiar: $\Box_i A$ is true at $x$ iff $A$ is true at every $R_i$-accessible possibility.

Humberstone treats $\Diamond$ as a defined connective, $\Diamond_i A$ just means $\neg \Box_i \neg A$, and I'll follow suit. If we just spell out what it means for $\neg \Box_i \neg A$ to be true, we get the rule [$\Diamond_i$]~Official~. But if we impose the above three constraints on $R_i$, we can see that this is equivalent to the more familiar [$\Diamond_i$]~Simple~.

\begin{align*}
[\Diamond_i]_{\text{Official}} \quad & \mathcal{M} \models_x \Diamond_i A \text{ iff } \forall y \geqslant x \, \exists z \geqslant y \, \exists w \, (z R_i w \text{ and } \mathcal{M} \models_w A). \\
[\Diamond_i]__{\text{Simple}} \quad & \mathcal{M} \models_x \Diamond_i A \text{ iff } \exists y \, (x R_i y \Rightarrow \mathcal{M} \models_y A);
\end{align*}

If $R_i$ obeys **RDown**, then [$\Diamond_i$]~Official~ will imply [$\Diamond_i$]~Simple~. For $\Diamond_i A$ to be true at $x$ according to [$\Diamond_i$]~Official~, there must be some refinement which can access a point where $A$ is true, and so by **RDown**, $x$ itself can access that point. If $R_i$ obeys **RRef++**, then [$\Diamond_i$]~Simple~ will imply [$\Diamond_i$]~Official~. If there is some $y$ such that $xR_iy$ and $A$ is true at $y$, then by **RRef++**, there is some refinement of $x$ such that every refinement of it can access $y$, and hence can access a point where $A$ is true. So these are equivalent.

From now on, I'll use [$\Diamond_i$]~Simple~ when working out what's true at points in particular models. But when we are proving general facts about the language, it will help to remember that $\Diamond_i$ is a defined connective, so we don't need an extra part of inductive arguments to cover it.

## Modal Constraints {-}

Why should we impose the three constraints Humberstone proposes? It is not hard to show that they guarantee that persistence and refinability hold for sentences generated using these new modal connectives. At least, it isn't hard as long as we remember that $\Diamond$ is being treated as defined, so the only new step in the inductive proofs involves $\Box$. And **UpR** guarantees persistence for $\Box$ sentences, while **RRef++** guarantees refinability.

But this is overkill. As Humberstone points out, we haven't used **RDown** in the proof, so this doesn't explain why we'd impose **RDown**. As Holliday points out [note to Claude, we need page number for this] **UpR** is stronger than we need for persistence. We could weaken it by making greater use of the fact that $A$ is persistent. All we need is that if $x \leqslant x'$ and $xRy$ then there is some $z \geqslant y$ such that $xRy$. That will guarantee the key fact if $x'$ can access a world where $A$, then so can $x$.

So we need other arguments for these constraints other than their role in ensuring persistence and refinability. Humberstone offers two other arguments here. One anticipates the multi-modal setting that is being used here. It's that if we want to use this system for tense logic, then we want $R_i^{-1}$ to satisfy all the constraints, so if we impose **UpR**, we should also impose **RDown**. This isn't convincing on its own though. For one thing, as already noted, we might not need **UpR**. For another, by these lights we should worry that the system is incomplete because we haven't put in a converse of **RRef++**.

The argument that Humberstone spends more time on, and which I think is more compelling, comes from rethinking the relationship between $R_i$ and $\Box_i$. It's very tempting to read those truth conditions as being explanatory from right-to-left. On this way of thinking, facts about which $\Box_i$ sentences are true at a point are grounded in which non-modal sentences are true and which $R_i$ relations obtain. But while this is tempting, it isn't compulsory. 

We could instead take the modal facts as given, and ask what accessibility relations must obtain to be consistent with them. The process here is familiar from the construction of canonical models. We take the sets of consistent sentences as given, and say $s_1R_is_2$ iff whenever $\Box_i A \in s_1$, then $A \in s_2$. Humberstone's approach is, I think, similar. Start with the idea that some sentences are true in some model $\mathcal{M}$ at possibilities $x$ and $y$, say $xR_iy$ iff $\mathcal{M} \models_y A$ whenever $\mathcal{M} \models_x \Box_i A$, and ask what constraints $R_i$ will thereby satisfy.

The answer is that, if all sentences are persistent and refinable, then $R_i$ will satisfy these three constraints. If $\mathcal{M} \models_y A$ whenever $\mathcal{M} \models_x' \Box_i A$, then by the persistence of $\Box_i$, we know that $\mathcal{M} \models_y A$ whenever $\mathcal{M} \models_x \Box_i A$. A similar argument, using the persistence of $A$, justifies **RDown**. Finally, **RRef++** follows from the fact that $\Box_i A$ is refinable. If $\Box_i A$ is not true at $x$, that means that it is determinately not true at some refinement. So if $\mathcal{M} \nmodels_x A$, there must be some refinement $x'$ such that for all further refinements $x''$, $\mathcal{M} \nmodels_x'' A$. If $\mathcal{M} \nmodels_x \Box_i A$, then there must be some possibility $y$ such that $xR_iy$ and $\mathcal{M} \nmodels_y A$. So as long as $x''R_iy$, refinability will be satisfied. I don't see how to prove there isn't a weaker condition that would also work, it's possible we could use the refinability of A to find some weaker condition, but I don't quite see how that would work. So I think **RRef++** also follows from this way of thinking about accessibility.

In the next section I'll discuss what logics can be defined using frames that satisfy all of these conditions.

# Logics Determinable on Humberstone Frames {#sec-proof}

@Holliday2025 [§8.2] raises an interesting question. As well as the familiar Kripke frames most commonly used as a semantics for modal logic, and the Humberstone frames defined above, he introduces a class of 'full possibility' frames, which weaken some of Humberstone's constraints. It won't matter here exactly what these weakenings are, but what does matter is that he shows that using these weakened frames, we can determine logics which are not determinable on any class of Kripke frames. To state this more precisely, for any class of frames $\mathsf{F}$, let $\mathrm{L}(\mathsf{F})$ be the set of sentences true at all points in all models definable some member of $\mathsf{F}$. Then let $\mathrm{ML}(\mathsf{F})$ be the set $\{\mathrm{L}(\mathsf{X}) : \mathsf{X} \subseteq \mathsf{F}\}$. That is $\mathrm{ML}(\mathsf{F})$ will be the class of logics which can be determined using just $\mathsf{F}$.

If we let $\mathsf{K}$ denote the class of Kripke frames, and $\mathsf{FP}$ denote the class of full possibility frames, @Holliday2025 [§2.5] constructs a very clever argument to show that $\mathrm{ML}(\mathsf{K}) \subsetneq \mathrm{ML}(\mathsf{FP})$. But, if we let $\mathsf{H}$ denote the class of Humberstone frames, he notes that while the fact that every Kripke frame is a Humberstone frame and every Humberstone frame is a full possibility frame, $\mathrm{ML}(\mathsf{K}) \subseteq \mathrm{ML}(\mathsf{H}) \subseteq \mathrm{ML}(\mathsf{FP})$, and while $\mathrm{ML}(\mathsf{K}) \subsetneq \mathrm{ML}(\mathsf{FP})$ implies that one of those inclusions is strict, it isn't clear which one. He leaves the question of which one it is, and of course it could be both, as an open question.

I don't have an answer to that question as asked, since it is asked about languages with sentences with finite lengths. I do have a proof that if we allow infinite disjunction, as discussed above, then $\mathrm{ML}(\mathsf{K}) \neq \mathrm{ML}(\mathsf{K})$. If we expand the language like that, at least the first inequality is strict. I will show this by constructing a single Humberstone frame that, in the infinitary language, defines a logic with no Kripke equivalent. The construction will follow Holliday's construction very closely, but differ just enough to ensure compliance with Humberstone's conditions.

## The Frame {-}

The frame is built from two copies of the set of finite binary sequences—sequences of 0s and 1s of any finite length, including the empty sequence. Call one copy the **left-handed** sequences and the other the **right-handed** sequences. The refinement relation is: $x \leqslant y$ iff $x$ and $y$ have the same handedness and $x$ is an initial segment of $y$. So within each copy the frame is just the binary tree ordered by extension, and no left-handed sequence refines a right-handed sequence or vice versa. It will help to have some notation for referring to points in this model. When $s$ is a finite binary sequence, I'll write $s^L$ for the left-handed version of $s$, and $s^R$ for the right-handed version.

## The Accessibility Relations  {-}

Next I'll define an accessibility relation and a separate infinite family of accessibility relations. The single relation, which I'll write $R^{\rightarrow}$ is such that $xR^{\rightarrow}y$ iff $x$ is left-handed and $y$ is right-handed. The family of relations, each of which I'll write as $R^{\rightarrow}_i$, for $i \in \mathbb{N}$, is such that $xR^{\leftarrow}_iy$ iff $x$ is right-handed, $x$ does not have a $0$ in its $i$-th position (either because $x$ has length less than $i$, or because it has a $1$ in position $i$), and $y$ is left-handed.

That $R^{\rightarrow}$ satisfies **UpR**, **RDown**, and **RRef++** is obvious. It is also obvious that for each $i$, $R^{\rightarrow}_i$ satisfies **UpR** and **RDown**. It's only a little harder to show that it satisfies **RRef++**. Assume $xR^{\rightarrow}_iy$. So $x$ is right-handed, and $y$ is left-handed. If $x$ is of length at least $i$, then $x$ itself can be the refinement such that every further refinement can access $y$. If $x$'s length is less than $i$, extend $x$ with enough 1s to create a sequence of length $i$. The result will be a refinement such that every refinement can access $y$, as required.

## The Example {-}

Now consider the proposition (\ref{Splitting}); a minor variant on Holliday's example (\textsc{Split}). (I'm using $\mathsf{T}$ for an arbitrary tautology.)

\begin{equation}
\neg \Diamond^{\rightarrow} p 
  \vee
\bigvee_{i \in \mathbb{N}}(
  \Diamond^{\rightarrow}
    (
      p
        \wedge
      \Diamond_i^{\leftarrow} \mathsf{T}
    )
  \wedge
  \Diamond^{\rightarrow}
    (
      p
        \wedge
      \neg \Diamond_i^{\leftarrow} \mathsf{T}
    )
  )
\tag{\textsc{Splitting}}
\label{Splitting}
\end{equation}

I'm going to make three claims about (\ref{Splitting}). First, it is true throughout the frame I just described. Second, $\neg \Diamond^{rightarrow} p$ is not true on all models on that frame. Third, there is no class of Kripke frames throughout which (\ref{Splitting}) is always true and $\neg \Diamond^{rightarrow} p$ is not always true. From this it follows that $\mathrm{ML}(\mathsf{K}) \neq \mathrm{ML}(\mathsf{K})$.

For the first claim, I'll show something slightly stronger, namely that at each point one or other disjunct in \ref{Splitting}) is true.


::: {.content-visible unless-format="html"}
## References {-}
:::
