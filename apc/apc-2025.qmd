---
title: "Age, Period, and Cohort Effects in Philosophy Journal Citations"
abstract: |
  There are extremely strong age and period effects in citations in philosophy journals. The age effect is that citations are concentrated on articles published two to five years prior. The period effect is that recent years have seen an explosion in the number of articles published, and the number of citations per articles, so many articles are getting more citations per year than they ever had previously. But cohort effects are trickier to detect. In this note I argue that they exist. There are more citations to articles from eras of more dramatic change in philosophy, such as around 1970 and around 2010. And there are fewer citations to articles from periods of consolidation, especially in the late 1970s through the 1980s.
execute:
  echo: false
  warning: false
date: February 12 2025
bibliography: 
 - /Users/weath/Documents/quarto-articles/brian-quarto.bib
 - /Users/weath/Documents/citations-2025/autobib.bib
number-sections: true
keep-tex: true
author:
  - name: Anon
format:
  html:
    fig-format: png
    fig-width: 10
    fig-height: 7
  docx:
    reference-doc: my-template.docx
  pdf: 
    geometry: "left=1in,right=1in,top=1in,bottom=1in"
    mathfont: EB Garamond Math
    mainfont: EB Garamond Math
    sansfont: EB Garamond SemiBold
    mainfontoptions: 
      - ItalicFont=EB Garamond Italic
      - BoldFont=EB Garamond SemiBold
    fontsize: 12pt
    linkcolor: black
    urlcolor: black
    colorlinks: false
    linestretch: 1.75
    link-citations: true
    output-file: "Age Period Cohort.pdf"
    include-in-header:
      text: |
        \setlength\heavyrulewidth{0ex}
        \setlength\lightrulewidth{0ex}
---

```{r}
#| label: loader
#| cache: false

require(tidyverse)
require(slider)
require(stringr)
require(knitr)
require(lsa)
require(wesanderson)

if(knitr::is_latex_output()) {
  knitr::opts_chunk$set(dev = 'cairo_pdf')
}

# Graph Themes
old <- theme_set(theme_minimal())
theme_set(old)
theme_update(plot.title = element_text(family = "Scala Pro", size = 24, face = "bold"),
             plot.subtitle = element_text(family = "Scala Sans Pro", size = 30),
             axis.text = element_text(family = "Scala Sans Pro", size = 18),
             title = element_text(family = "Scala Sans Pro", size = 18),
             plot.background = element_rect(fill = "#F9FFFF"),
             panel.background = element_rect(fill = "white"),
             legend.background = element_rect(fill = "#F9FFFF"),
             panel.grid = element_line(color = "grey92"),
             legend.text = element_text(family = "Scala Sans Pro", size = 20),
             strip.text = element_text(family = "Scala Sans Pro", size = 20),
             legend.key.spacing.y = unit(0.5, 'lines'),
             legend.key.spacing.x = unit(1, 'cm')
  )

if(knitr::is_latex_output()) {
theme_update(axis.title = element_text(family = "EB Garamond", size = 11),
             plot.title = element_text(family = "Europa-Bold", size = 14),
             plot.subtitle = element_text(family = "EB Garamond", size = 11),
             axis.text = element_text(family = "EB Garamond", size = 10),
             plot.background = element_rect(fill = "white"),
             panel.background = element_rect(fill = "white"),
             legend.background = element_rect(fill = "white"),
             panel.grid = element_line(color = "grey92"),
             legend.text = element_text(family = "EB Garamond", size = 11),
             strip.text = element_text(family = "EB Garamond", size = 12),
             legend.key.spacing.y = unit(-0.3, 'lines'),
             legend.key.spacing.x = unit(0, 'cm')
  )
}
```

```{r}
#| label: buildgraphs
#| cache: false

load("/Users/weath/Documents/citations-2025/philo_bib.RData")
load("/Users/weath/Documents/citations-2025/philo_cite.RData")

start_year <- 1955
end_year <- 2021
min_data <- 5

# New attempt
# Two categories: available and typical
# Available means published before citing article
# Typical means published 3-10 years before citing article
# The 3 is because weird things have happened with recent cites in recent years

typical_low <- 3
typical_high <- 10

# This sets the color for one-color graphs

point_col <- wes_palette("AsteroidCity1")[3]

active_philo_bib <- philo_bib |>
  filter(year >= start_year, year <= end_year)

active_philo_cite <- philo_cite 

article_years <- active_philo_bib |>
  as_tibble() |>
  select(id, year)

citation_tibble <- active_philo_cite |>
  as_tibble() |>
  rename(new = id, old = refs) |>
  left_join(article_years, by = c("old" = "id")) |>
  rename(old_year = year)  |>
  left_join(article_years, by = c("new" = "id")) |>
  rename(new_year = year) |>
  filter(old_year >= start_year,
         new_year <= end_year,
         old_year >= start_year,
         new_year <= end_year)

# Now a tibble of how many times articles in year x are cited in year y

year_in_year_out <- citation_tibble |>
  group_by(old_year, new_year) |>
  tally(name = "citations") |> # Now add the 'missing' pairs
  ungroup() |>
  complete(old_year, new_year, fill = list(citations = 0)) 

# This works out how many citations there are each year to 3-10 year old articles

citations_in_typical_year <- year_in_year_out |>
  mutate(age = new_year - old_year) |>
  filter(age >= typical_low, age <= typical_high) |>
  group_by(new_year) |>
  summarise(typical_citations = sum(citations)) 

# This works out how many citations there are each year to non-negative age articles

citations_in_available_year <- year_in_year_out |>
  mutate(age = new_year - old_year) |>
  filter(age >= 0) |>
  group_by(new_year) |>
  summarise(available_citations = sum(citations)) 

# Tibble for raw citation age

raw_age_tibble <- citation_tibble |>
  mutate(age = new_year - old_year) |>
  group_by(age) |>
  tally(name = "count")

raw_age_plot <- raw_age_tibble |>
  ggplot(aes(x = age, y = count)) +
  geom_point(color = point_col) + # Using geom_line makes it not obvious how many points there are, because it is *so* straight
  xlab('Age of citation') +
  ylab('Number of citations')

# I'm going to count the 'typical' articles as those published between 3 and 10 years before the citing year
# The 'available' articles are those published before the time

# Tibble for number of publications each year, and cumulative, or 'available'

articles_per_year <- active_philo_bib |>
  rename(old_year = year) |>
  group_by(old_year) |>
  tally(name = "articles") |>
  mutate(available = cumsum(articles)) |>
  mutate(typical_articles = slide_dbl(articles, sum, .before  = typical_high) - slide_dbl(articles, sum, .before = typical_low - 1))

articles_per_year_plot <- articles_per_year |>
  ggplot(aes(x = old_year, y = articles)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Number of indexed articles")

available_plot <- articles_per_year |>
  ggplot(aes(x = old_year, y = available)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Number of available indexed articles")

typical_plot <- articles_per_year |>
  ggplot(aes(x = old_year, y = typical_articles)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Number of typical indexed articles")

# Same for citations

all_citations_per_year <- citation_tibble |>
  group_by(new_year) |>
  tally(name = "citations") 

all_citations_per_year_plot <- all_citations_per_year |>
  ggplot(aes(x = new_year, y = citations)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Citations to indexed articles")

available_citations_per_year <- citation_tibble |>
  filter(new_year >= old_year) |>
  group_by(new_year) |>
  tally(name = "citations") 

available_citations_per_year_plot <- available_citations_per_year |>
  ggplot(aes(x = new_year, y = citations)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Citations to available indexed articles")

typical_citations_per_year <- citation_tibble |>
  filter(new_year >= old_year + typical_low, new_year <= old_year + typical_high) |>
  group_by(new_year) |>
  tally(name = "citations") 

typical_citations_per_year_plot <- typical_citations_per_year |>
  ggplot(aes(x = new_year, y = citations)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Citations to indexed articles from typical years")


# Outbound citations

outbound_citations <- left_join(
  articles_per_year,
  all_citations_per_year,
  by = c("old_year" = "new_year")
) |>
  mutate(outbound_rate = citations/articles) |>
  mutate(outbound = round(outbound_rate, 2))

outbound_citations_plot <- outbound_citations |>
  filter(old_year != 1955) |>
  ggplot(aes(x = old_year, y = outbound)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Outbound citations per indexed articles")

# Citations per typical article

available_citation_rate_per_year <- available_citations_per_year |>
  left_join(articles_per_year, by = c("new_year" = "old_year")) |>
  #filter(new_year >= start_year + typical_high) |>
  left_join(citations_in_available_year, by = "new_year") |>
  mutate(mean_cites = available_citations/available)

available_citation_rate_per_year_plot <- available_citation_rate_per_year |>
  ggplot(aes(x = new_year, y = mean_cites)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Annual citation rate of available articles.")

typical_citation_rate_per_year <- typical_citations_per_year |>
  left_join(articles_per_year, by = c("new_year" = "old_year")) |>
  #filter(new_year >= start_year + typical_high) |>
  left_join(citations_in_typical_year, by = "new_year") |>
  mutate(mean_cites = typical_citations/typical_articles)

typical_citation_rate_per_year_plot <- typical_citation_rate_per_year |>
  ggplot(aes(x = new_year, y = mean_cites)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Annual citation rate of typical articles.")

# How many articles each year are never cited 

list_of_cited_articles <- citation_tibble |> group_by(old) |> tally() |> arrange(old)

never_cites <- active_philo_bib |>
  arrange(id) |>
  anti_join(list_of_cited_articles, by = c("id" = "old")) |>
  group_by(year) |>
  tally(name = "never_cited") |>
  rename(old_year = year)

never_cites_graph <- never_cites |>
  ggplot(aes(x = old_year, y = never_cited)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Number of uncited articles published each year.")

never_cited_total <- sum(never_cites$never_cited)

percent_uncited <- never_cites |>
  left_join(articles_per_year, by = "old_year") |>
  mutate(uncited_ratio = never_cited/articles)

percent_uncited_plot <- percent_uncited |>
  ggplot(aes(x = old_year, y = uncited_ratio)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Proportion of uncited articles each year") +
  ylim(c(0,1))

# Plot how often articles are cited - final graph is log on both dimensions, and some jitter added

article_times_cited <- citation_tibble |>
  group_by(old) |>
  tally(name = "citations")

count_of_citations <- article_times_cited |>
  ungroup() |>
  group_by(citations) |>
  tally(name = "number_of_articles")

count_of_citations_plot <- count_of_citations |>
  ggplot(aes(x = citations, y = number_of_articles)) +
  xlab("Number of times cited") +
  ylab("Number of articles") +
  scale_x_log10() +
  scale_y_log10() +
  geom_jitter(height = 0.05, color = point_col)

# Same for number of outbound citations in each article

article_times_citing <- citation_tibble |>
  group_by(new) |>
  tally(name = "citations")

count_of_citations_out <- article_times_citing |>
  ungroup() |>
  group_by(citations) |>
  tally(name = "number_of_articles")

count_of_citations_out_plot <- count_of_citations_out |>
  ggplot(aes(x = citations, y = number_of_articles)) +
  xlab("Number of outbound citations") +
  ylab("Number of articles") +
  scale_y_log10() +
  geom_jitter(height = 0.05, color = point_col)

# Citations between years
ct_sum <- citation_tibble |>
  group_by(old_year, new_year) |>
  tally(name = "citations") |>
  ungroup()

# All citations to typical articles in a year
ct_all <- citation_tibble |>
  filter(new_year >= old_year + typical_low, new_year <= old_year + typical_high) |>
  group_by(new_year) |>
  tally(name = "typical_citations")

age_effect_tibble <- year_in_year_out |>
  filter(old_year >= start_year, old_year <= end_year + 1 - min_data, new_year >= start_year + typical_high) |>
  filter(new_year >= old_year) |>
  left_join(select(articles_per_year, old_year, articles), by = "old_year") |>
  left_join(select(articles_per_year, old_year, typical_articles), by = c("new_year" = "old_year")) |>
  left_join(ct_all, by = "new_year") |> 
  mutate(age = new_year - old_year) |>
  mutate(cite_ratio = (citations/articles)/(typical_citations/typical_articles))

age_effect_tibble_plot <- age_effect_tibble |>
  filter(old_year >= start_year + 1, old_year <= end_year - min_data, new_year >= start_year) |>
  ggplot(aes(x = new_year, y = cite_ratio)) +
  geom_point(size = 0.25, color = point_col) +
  facet_wrap(~old_year, ncol = 6) +
  xlab(element_blank()) +
  ylab(element_blank()) +
  theme(axis.text = element_text(size = 10),
        strip.text = element_text(size = 12))

max_ratio_finder <- age_effect_tibble |>
  group_by(old_year) |>
  summarise(maxrat = max(cite_ratio)) |>
  ggplot(aes(x = old_year, y = maxrat)) +
  geom_point(color = point_col) +
  xlab(element_blank()) +
  ylab("Maximum citation ratio") +
  ylim(c(0, 3))

age_at_max_ratio <- age_effect_tibble |>
  group_by(old_year) |>
  filter(cite_ratio == max(cite_ratio))

age_at_max_ratio_plot <- age_at_max_ratio |>
  filter(old_year <= 2016, old_year >= start_year + typical_high - 2) |>
  ggplot(aes(x = old_year, y = age)) +
  geom_point(color = point_col) +
  xlab(element_blank()) + 
  ylab("Age at maximum citation ratio") +
  scale_y_continuous(limits = c(0, 14), breaks = 1:4 * 4)

# Function for finding Mode that I got from Stack Exchange
# https://stackoverflow.com/questions/2547402/how-to-find-the-statistical-mode

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

median_age_each_year <- citation_tibble |>
  mutate(age = new_year - old_year) |>
  group_by(new_year) |>
  summarise(med_age = median(age),
            mod_age = Mode(age))


median_plot <- median_age_each_year |>
  filter(new_year >= 1970) |>
  ggplot(aes(x = new_year, y = med_age)) +
  geom_point(color = point_col) +
  xlab(element_blank()) + 
  ylab("Median age of citations each year") +
  scale_y_continuous(limits = c(0, 14), breaks = 1:4 * 4)

modal_plot <- median_age_each_year |>
  filter(new_year >= 1970) |>
  ggplot(aes(x = new_year, y = mod_age)) +
  geom_point(color = point_col) +
  xlab(element_blank()) + 
  ylab("Modal age of citations each year") +
  scale_y_continuous(limits = c(0, 14), breaks = 1:4 * 4)

age_effect_grouped <- age_effect_tibble |>
  filter(new_year >= old_year) |>
  filter(new_year <= old_year + end_year - start_year + 1 - min_data) |>
  mutate(age = new_year - old_year) |>
  group_by(age) |>
  summarise(mean_effect = mean(cite_ratio))

age_effect_tibble_adj <- age_effect_tibble |>
  mutate(age = new_year - old_year) |>
  filter(age <= end_year - start_year - min_data) |>
  left_join(age_effect_grouped, by = "age")

age_effect_grouped_plot <- age_effect_grouped |>
  ggplot(aes(x = age, y = mean_effect)) +
  geom_point() +
  xlab("Article age") +
  ylab("Mean citation ratio")

age_effect_everything_plot <- age_effect_tibble_adj |>
  filter(old_year >= 1975, old_year != 1973) |>
  ggplot(aes(x = age, y = cite_ratio, color = as.factor(old_year))) +
  geom_jitter(size = 0.5, alpha = 0.7) +
  # geom_jitter(aes(size=(old_year==2008 | old_year == 1985), shape = (old_year==2008)), alpha = 1) +
  #  geom_jitter(aes(size=(old_year %in% c(1978, 1980, 1985, 1987)), alpha = 1)) +
  # scale_size_manual(values=c(0.3,2)) +
  xlab("Age of cited articles") +
  ylab("Citation ratio") +
  geom_line(aes(x = age, y = mean_effect), color = point_col) +
  geom_point(aes(x = age, y = mean_effect), color = point_col, size = 0.4) +
  theme(legend.position = "none")

year_by_year_with_effect <- year_in_year_out |>
  filter(new_year >= old_year) |>
  filter(new_year <= end_year) |>
  filter(old_year >= start_year, old_year <= end_year - min_data + 1, new_year >= start_year + typical_high) |>
  mutate(age = new_year - old_year) |>
  filter(age <= end_year - start_year - min_data) |>
  left_join(age_effect_grouped, by = "age") |>
  left_join(
    select(
      age_effect_tibble, old_year, new_year, cite_ratio
    ), by = c("old_year", "new_year")
  ) |>
  mutate(surplus = cite_ratio - mean_effect) |>
  arrange(-surplus)

# The next one calculates the difference between each year and the average. 
# But this has odd effects at the periphery, and compares each year to something it is part of.
# Below, in yiyo_extended, I try to work out what happens when each year is compared to the other years
# This is more work because you have to calculate the 'other years' value again each time

year_by_year_average <- year_by_year_with_effect |>
  group_by(old_year) |>
  summarise(mean_surplus = mean(surplus))

year_by_year_average_plot <- year_by_year_average |>
  ggplot(aes(x = old_year, y = mean_surplus)) +
  geom_point()  +
  geom_smooth() +
  xlab(element_blank()) +
  ylab("Mean annual citations above average") +
  scale_y_continuous(labels = scales::percent)

# year_by_year_average_plot + geom_smooth()

effect_by_age_average <- function(early, late){
  age_effect_tibble |>
    filter(age >= early, age <= late) |>
    #    add_count(old_year, name = "data_points") |>
    #    filter(data_points >= min_data) |>
    group_by(old_year) |>
    summarise(mean_ratio = mean(cite_ratio)) |>
    ggplot(aes(x = old_year, y = mean_ratio)) +
    geom_point() +
    geom_smooth() +
    xlab(element_blank()) +
    ylab(element_blank()) +
    labs(title = case_when(
      early == late ~ paste0("Citation ratio at age ", early),
      TRUE ~ paste0("Mean citation ratio from ages ",early," to ",late)))
}

effect_by_age_facet <- function(early, late){age_effect_tibble |>
    filter(age>= early, age <= late) |>
    ggplot(aes(x = old_year, y = cite_ratio)) +
    geom_point() + geom_smooth() +
    facet_wrap(~age, ncol = 4)
}

year_to_mean_plot <- function(the_year){
  age_effect_tibble_adj |>
    filter(old_year == the_year) |>
    ggplot(aes(x = age, y = cite_ratio)) +
    geom_point(size = 2, alpha = 1, color = hcl(h = (the_year-1975)*(360/43)+15, l = 65, c = 100)) +
    # geom_jitter(aes(size=(old_year==2008 | old_year == 1985), shape = (old_year==2008)), alpha = 1) +
    #  geom_jitter(aes(size=(old_year %in% c(1978, 1980, 1985, 1987)), alpha = 1)) +
    # scale_size_manual(values=c(0.3,2)) +
    xlab("Age of cited articles") +
    ylab("Citation ratio") +
    geom_line(aes(x = age, y = mean_effect), color = point_col) +
    geom_point(aes(x = age, y = mean_effect), color = point_col, size = 0.4) +
    theme(legend.position = "none")
}
```

# Introduction {#sec-introduction}

Before looking at the data, here are two things I believed about philosophy citations. First, philosophers tend to cite very old papers. We still regularly teach a number of papers over half a century old in introductory classes; e.g., @Frankfurt1969, @Thomson1971, @Singer1972, @Lewis1973ben. These aren't taught as history papers, but as early entries into the contemporary philosophical debate. And, I thought, that's how we cite. Second, the technological changes of the last quarter century meant that this practice was being slowly reversed. The spread of electronic communication in the late 20th century, and then the rise of archives (e.g., Arxiv, SSRN, PhilPapers) and eventually journals publishing in EarlyView, meant that papers could now be cited even before they were published, and certainly without the delays involved in printing and posting journals around the world.

Both of these thoughts were wrong. Historically, philosophy papers have tended, when they are citing other philosophy papers, to cite very recent ones. But this tendency is diminishing, not increasing, over time. I'll offer much more evidence for these claims as we go along, but to make them plausible, I'll start with two simple graphs.

The data for the graphs come from citation data I downloaded concerning XXX papers published from 1955-2021,^[I would like to have more recent data, but this is the latest full year of data available through my university's contract with Web of Science. I do have substantial partial data for 2022, and it mostly confirms the trends shown here. But in this case I think it's better to leave off partial data than to try to correct for its incompleteness.] in one hundred leading philosophy journals. I focussed on the citations to and from journals in this dataset. So every citation is from one of these 100 journals between 1955 and 2021, and to one of these 100 journals between 1955 and 2021. (The details of the journals, including when they start getting indexed for this dataset, are in @sec-methodology.) In total, that gives us YYY citations.

Say the *age* of a citation is the difference between the publication year of the citing article and the cited article. So if an article published in 1998 cites an article published in 1985, that's a 13 year old citation.

In @fig-overall-age I've plotted the number of citations in the dataset with each possible age. As you can see, it's very heavily tilted towards the left-hand edge. It is true that people still cite @Frankfurt1969. Indeed, it's one of the most cited papers in the last ten years. But it's just one paper; the bulk of citations are to recently published papers which, if history is any guide, will soon stop collecting citations.

```{r}
#| label: fig-overall-age
#| fig-cap: "Number of citations with each age."

raw_age_plot
```

In @fig-overall-median-mode I've plotted the median and mode age of citations in each year from 1980 onwards. Before that the numbers are even lower, but since I'm only looking at citations to articles published after 1955 (or later if Web of Science started indexing the journal later than that), this is arguably an artifact of how I'm collecting the data. From 1980 onwards, however, there are many older articles that could be, but are not, getting cited. The upwards trends in both graphs look like a real change in citation practices, and not in the direction I antecedently expected.

```{r}
#| label: fig-overall-median-mode
#| fig-cap: "Summary statistics for outbound citations each year 1970-2021."
#| fig-subcap: 
#|   - "Median"
#|   - "Mode"
#| layout-ncol: 1

median_plot
modal_plot
```

There is a third surprise in the data, but it's a little more equivocal, and I'm not sure what to make of it. The 2010s seemed like, and to be honest still seem like, something of a golden age for philosophy. In metaphysics we saw the biggest paradigm shift in many years, away from modality and towards grounding. We saw the growth of important fields of social philosophy, including social epistemology, social metaphysics, and social philosophy of language. Though there were some earlier papers that have become important to the latter two fields (e.g., @Haslanger2000, and @Langton1993), it would have been a stretch to even call them 'fields' before 2010. Social epistemology was always a bit bigger, and you could point to earlier field defining work by, e.g., Jennifer @Lackey2008 and Adam @Elga2007. But it grew phenomenally in the 2010s. I'd predicted that would show up in higher citations to work in the 2010s, as these changes were consolidated. The data are a bit messy, and it would be good to have much more data, but this does not look to have happened. There isn't as neat a graph for this, however, and we'll return to this point at the end.

# Age, Period, and Cohort {#sec-apc-described}

To help understand the citation patterns, I'll borrow some terminology that's common in both sociology and medicine. Imagine that we see, in the historical record, some interesting patterns among teenagers in the late 1960s, and we're wondering what could explain the pattern. Two types of pattern spring immediately to mind, along with ways to test them.

First, the behaviour could be explained by the fact the people involved are teenagers. If so, it is an **age effect**. The natural way to test this is to see if similar patterns show up with teenagers at different times.

Second, the behaviour could be explained by the fact that it was the 1960s, and lots of striking things happened in the 1960s. If so, it is a **period effect**. The natural way to test this is to see if the same pattern shows up with non-teenagers in the 1960s.

There is an important third kind of explanation. The people involved are born in the early 1950s, so they are part of the post-war baby boom. Colloquially, they are boomers. Maybe that could explain the pattern we see. If so, it is a **cohort effect**. The natural way to test this is to see if the same pattern shows up if we look at the same people in other stages of their life.

It's easy to overlook the importance of cohort effects. Sometimes they simply look like age effects. @GhitzaEtAl2023 argue that many hypotheses about age effects on voting, e.g., that older people are more naturally conservative, are really just cohort effects. @Bump2023 argues that understanding the distinctive role the boomers in particular play is crucial for understanding many aspects of modern American life.

There are mathematical reasons that it is hard to tease these effects apart too. Many statistical techniques for separating out influences start to fall apart when there are linear correlations between combinations of variables. In this case there is as tight a correlation as is possible. By definition, cohort plus age equals period. There are some things you can do to get around this problem - see @KeyesEtAl2010 for a useful survey of some of the options - but it remains a challenge.

Even conceptually, it is hard to separate out these three effects in cases where there is evidence that the strength of the effects changes over time. As I noted at the start, the natural way to test hypotheses about which effect is strongest involve looking at other times. That works well when the age effects are constant. When they are not (and they might not be here), it is harder.

For most of our story, however, it helps just to have these three effects in mind. Using them, we can summarise the data reasonably quickly.

- The age effect is that articles get cited most when they are two to five years old, as shown in @fig-overall-age.
- The period effect is that there are many more citations in recent years than in earlier years. This is in part because the number of articles published in these journals has been growing, and in part because the number of citations per article grew substantially over the 2000s and 2010s, and exploded in the 2020s.
- The cohort effect is that articles from the 1970s and 2000s get cited more than you'd expect given these age and period effects, articles from before the late-1960s get barely cited at all, and articles from 1980 through the mid-1990s also get cited considerably less than articles either side of that period. I'll offer some speculations at the end of the paper about the philosophical causes of, and consequences of, these cohort effects.

As I mentioned above, I'll go over the methodology in detail in @sec-methodology. But there is one point that is important to note before we start. I'm using data from Web of Science, and they typically don't start indexing journals until well after the journal is established. So the first year of citation data I have for _Analysis_ is 1975. Crucially, that means that "Is Knowledge Justified True Belief?" [@Gettier1963] is not included in this study. If it were, and in general if I had the data from _Analysis_ to work from, some of the results about the early 1960s would look less dramatic, though as far as I can tell, the direction of the results wouldn't change.

# Period Effects {#sec-period}

Those  `{r} nrow(citation_tibble)` citations are not distributed evenly over time. Instead, they grow rapidly. At the start, in 1956, there are only `{r} filter(all_citations_per_year, new_year == 1956)$citations` citations. That's not too surprising; without the ability to cite preprints, there aren't going to be many citations of articles that have come out that year. By 2021, there are `{r} filter(all_citations_per_year, new_year == 2021)$citations`. In @fig-citationsperyear, I show how these grew; the striking thing to me is the big jump between 2020 and 2021.

```{r}
#| label: fig-citationsperyear
#| fig-cap: "The number of citations in the dataset made each year."

all_citations_per_year_plot
```

What explains this dramatic growth? Part of the explanation is that more articles are being published, and more articles are being indexed. @fig-articlesperyear shows how many articles are in the dataset each year.

```{r}
#| label: fig-articlesperyear
#| fig-cap: "The number of articles in the dataset published each year."

articles_per_year_plot
```

That explains some of the growth, but not all of it. The curve in @fig-articlesperyear is not nearly as steep as the curve in @fig-citationsperyear. The number of (indexed) citations per article is also rising. In @fig-outboundcitations I've plotted the average number of citations to other articles in the dataset each year.

```{r}
#| label: fig-outboundcitations
#| fig-cap: "The average number of citations to indexed articles each year."

outbound_citations_plot
```

There are a few possible explanations for the shape of this graph.

At the left-hand edge, there are obvious boundary effects. Since we're only counting citations to articles published since 1956, it isn't surprising that there aren't very many of them per article in the 1950s. Since articles rarely get unpublished, there are more articles available to cite every year.

That can't explain the massive jumps we see at the right hand edge of @fig-outboundcitations. The jump there looks like the convergence of two cultural trends. One is a trend simply to greater numbers of citations. The most casual perusal of journals will confirm that trend. The other is a trend to greater citations of journals themselves, as opposed to books or edited volumes.

A sharp jump like this is a warning sign that there is something wrong with the data. It's impractical to cross-check every entry, but those I have checked look correct. The change seems led by the most prestigious journals. For each journal I calculated the average number of outbound citations (to these hundred journal) for both the 2010s, and the first two years of the 2020s. The ten journals with the largest increase between the decades are shown in @tbl-large-growth.

```{r}
#| label: tbl-large-growth
#| tbl-cap: "Mean outbound citations for some journals over the last two decades."

who_cites_more <- citation_tibble |>
  left_join(
    select(
      philo_bib,
      id,
      journal
    ), by = c("new" = "id")
  ) |>
  filter(new_year >= 2010, new_year <= 2021) |>
  mutate(period = case_when(
    new_year < 2020 ~ "2010-2019",
    TRUE ~ "2020-2021"
  )) |>
  group_by(journal, period) |>
  summarise(articles = n_distinct(new), citations = n(), .groups = "drop") |>
  mutate(name_len = str_length(journal)) |>
  mutate(mean_cites = citations/articles) |>
  pivot_wider(id_cols = c(journal, name_len), names_from = period, values_from = mean_cites) |>
  mutate(diff = `2020-2021` - `2010-2019`) |>
  mutate(Difference = round(diff, 1),
         `2010-2019` = round(`2010-2019`, 1),
         `2020-2021` = round(`2020-2021`, 1)) |>
  arrange(-diff) |>
  slice(1:10) |>
  select(Journal = journal,
         `2010-2019`,
         `2020-2021`,
         Difference)

kable(who_cites_more)

```

Since _Philosophical Review_ only publishes 10 to 12 articles per year, it is not surprising that it shows the most variation on this list. Still, the change in the 2010s isn't only small sample size variation. Of the 22 articles it published in 2020 and 2021, only one of them [@WOS000575210400003] had fewer than 14.8 outbound citations. With a sample of just 22 anything could happen, but it would be surprising to have all but one end up on the same side of the historical average by chance.

Although the number of citations is going up, the number of articles available to be cited is also going up. Say an article is _available_ if it is published in a year iff it is published in or before that year. That's not quite right in either direction; some articles are cited before publication, some articles that come out in December aren't in any real sense available to be cited in January. But it's close enough. Say an article is from a year that is _typically_ cited iff it is between 3 and 10 years before the citing year. This notion will play a big role in @sec-age; I'm going to use these as a way of getting something like a base rate for citations in a given year. Using these definitions, @fig-articlecounts shows how many articles are available to be cited each year, and are from years that are typically cited.

```{r}
#| label: fig-articlecounts
#| fig-cap: "Article counts."
#| fig-subcap: 
#|   - "Available articles"
#|   - "Typically cited articles"
#| layout-ncol: 1

available_plot
typical_plot
```

In @fig-citationcounts, I've shown how often, in each year, the available articles, and the 'typical' articles are cited. The 'available' graph is obviously similar to @fig-citationsperyear; under 1% of citations are to articles published in future years. One thing that will be useful in @sec-age is that the graphs in @fig-citationcounts have a similar shape.

```{r}
#| label: fig-citationcounts
#| fig-cap: "Citation counts."
#| fig-subcap: 
#|   - "Citations to available articles"
#|   - "Citations to typical articles"
#| layout-ncol: 1

available_citations_per_year_plot 
typical_citations_per_year_plot
```

Putting all these together we can work out how often, on average, available articles, and typical articles, are cited in each year. The results are in @fig-citationrate.

```{r}
#| label: fig-citationrate
#| fig-cap: "Mean annual citations to different article kinds."
#| fig-subcap: 
#|   - "Available articles"
#|   - "Typical articles"
#| layout-ncol: 1

available_citation_rate_per_year_plot 
typical_citation_rate_per_year_plot 

```

Three things stand out about @fig-citationrate. One is that the two graphs have pretty similar shapes. Using citations from 3 to 10 years prior to the citing year is a pretty good proxy for all citations, and it turns out to be stable in other ways. A second is that both graphs are fairly flat for a long time. Between the mid 1970s and early 2000s they bounce around without moving much. Then they take off, and go through the roof in 2021. The other thing is that these are low numbers. For most of this study, an arbitrary article in one of these hundred journals was cited in one of those journals once a _decade_. Actually, since citation rates are extremely long-tailed, and mean rates are well above medians, that somewhat overstates how often the 'average article' was being cited. Frequent citation is very much not the norm.^[In the long run the average number of times an article is cited equals the average number of citations per article. So it shouldn't be too surprising that most article have just a handful of citations in philosophy journals.]

The various period effects are substantial; to get an reliable picture of the trends in citation patterns, we're going to have to allow for them. The project here is to use citation data as a proxy for philosophical influence. It is, of course, a deeply imperfect proxy. But it is better than most other proxies; it is certainly better than going off of vibes, or of what one's friends are talking about.^[In North America, placement on graduate syllabi might be an even better proxy, but that data is hard to collect, and we'd need a different measure for other countries.] If we're going to use citations this way though, we need to think about how to take into account the changes shown in @fig-citationsperyear. I'm going to offer a proposal in terms of typical articles; to a first approximation, I'll measure an article's influence in a period by the ratio of how often it is cited to how often a typical article is cited. This is a little arbitrary, but I think it gets things at least roughly right. At the very least, it avoids the problems with three other natural proposals that I'll now present, and probably anything that avoids these problems will be fairly similar.

Start with the non-proposal of just using citations per year as a measure of influence. Simply eyeballing @fig-citationsperyear makes that a little implausible; there would be so much more influence now. It also has some implausible particular consequences. Tyler Burge's "Individualism and Psychology" [@WOSA1986AYX3200001] was the fourth most cited paper of the 1990s, and if anything that understates its influence. In the 1990s (in these 100 journals) it had 68 citations, so 6.8 per year. In 2021, it had 7 citations, so slightly more per year. Now Burge's paper is still influential, and it connects in interesting ways to the social turn in philosophy that I'll discuss below, but it's implausible to say that it was more influential in 2021 than it was in the 1990s. When there are so many articles published, and a much lower bar to citation, seven citations a year doesn't signify as much influence.

A natural second proposal then is to measure what proportion of the year's citations any particular article has. By this measure, "Individualism and Psychology" was about twenty times as influential in the 1990s as in 2021, which isn't obviously false.^[To be clear, the database contains about twice as many citations in 2021 as in the whole of the 1990s.] Other cases, however, suggest this is too much of a correction. It's true that there are more citations now than there used to be. There are also more articles for these citations to be shared between. Holding fixed how influential an article is, you'd expect it to have a lower share of the citations when there are several times more articles available to be cited.

Again, it's easiest to see this with some examples. In @tbl-comp-cite-rate, I've shown the five most cited articles for the 1990s (on the top), and for 2021 (on the bottom). I've also shown how often each is cited per 1000 citations, i.e., the proportion of citations each article gets. And I've extended the first table to make it easier to compare the scales.

```{r}
#| label: tbl-comp-cite-rate
#| tbl-cap: "Most cited articles in the 1990s, and in 2021."
#| tbl-subcap: 
#|   - "1990s"
#|   - "2021"
#| layout-ncol: 1

nineties_cites_data <- citation_tibble |>
  filter(new_year >= 1990, new_year <= 1999) |>
  group_by(old) |>
  tally(name = "citations") |>
  ungroup() |>
  mutate(all_cite = sum(citations)) |>
  mutate(cite_rate = round(
    citations*1000/all_cite,
    2)) |>
  arrange(-cite_rate) |>
  mutate(Article = paste0(
    "@",
    str_replace_all(old,":","")
  )) |>
  mutate(Rank = row_number()) |>
  select(Rank,
         Article,
         Citations = citations,
         `Citations per 1000` = cite_rate) 

nineties_cites_kable <- nineties_cites_data |>
  slice(1:4) |>
  add_row(
    Rank = NA,
    Article = "...",
    Citations = NA,
    `Citations per 1000` = NA
  ) |>
  add_row(
    nineties_cites_data |>
      slice(10)
  ) |>
  add_row(
    Rank = NA,
    Article = "...",
    Citations = NA,
    `Citations per 1000` = NA
  ) |>
  add_row(
    nineties_cites_data |>
      slice(34:36)
  )

lastyear_cites_data <- citation_tibble |>
  filter(new_year >= 2021, new_year <= 2021) |>
  group_by(old) |>
  tally(name = "citations") |>
  ungroup() |>
  mutate(all_cite = sum(citations)) |>
  mutate(cite_rate = round(
    citations*1000/all_cite,
    2)) |>
  arrange(-cite_rate) |>
  mutate(Article = paste0(
    "@",
    str_replace_all(old,":","")
  )) |>
  mutate(Rank = row_number()) |>
  select(Rank,
         Article,
         Citations = citations,
         `Citations per 1000` = cite_rate)

lastyear_cites_kable <- lastyear_cites_data |>
  slice(1:10)

options(knitr.kable.NA = '')

kable(nineties_cites_kable)
kable(lastyear_cites_kable)
```

As influential as "A Matter of Individuality", "Counterfactual Dependence and Time's Arrow", and "Belief and the Will" were in the 1990s, I don't think they were more influential than all but one article was in 2021. Haslanger's article became a foundational text for one of the biggest fields in philosophy: social metaphysics. A measure of influence that puts it behind how influential 36 articles were in the 1990s seems wrong, and the intuitive reasoning about sharing citations around suggests why it is wrong.

A natural next move is to scale the citations not to all citations, but to the average number of citations that available, i.e., already published, articles get. This would solve the problem I just presented in a simple way. Having 1 cite per 1000 citations means a lot more when there are 100,000 articles that could have received that citation than when there are 10,000 such articles.

Again, this is an overcorrection. In theory, any article already published could be cited. In practice, long forgotten articles are long forgotten and hence not cited, and most articles are long forgotten. It's true that in 2021 articles have to 'share' citation space with more other articles. But in practice that normally means they share the space with other _recently published_ articles.

We can sort of see this by redoing the calculation from @tbl-comp-cite-rate, instead using the ratio of citations this article receives to citations the average available article receives.^[On the first part of @tbl-comp-cite-ratio, I calculated this ratio for each year, and then displayed the average over the decade.] I've done this in @tbl-comp-cite-ratio. First, I've shown the articles that, across the 1990s, had the highest average ratio of citations they received to citations the average available article received, and second, I did the same calculation for 2021.

```{r}
#| label: tbl-comp-cite-ratio
#| tbl-cap: "Most cited articles in the 1990s compared to average citations, and in 2021."
#| tbl-subcap: 
#|   - "1990s"
#|   - "2021"
#| layout-ncol: 1

avail_90s_cites_data <- citation_tibble |>
  filter(new_year >= 1990,
         new_year <= 1999) |>
  group_by(old, new_year) |>
  tally(name = "citations") |>
  ungroup() |>
  complete(old, new_year,
           fill = list(citations = 0),
           explicit = FALSE) |>
  group_by(new_year) |>
  mutate(all_cite = sum(citations)) |>
  ungroup() |>
  left_join(
    select(
      articles_per_year,
      new_year = old_year,
      available
    ), by = "new_year"
  ) |>
  mutate(cite_ratio = citations * available /all_cite) |>
  group_by(old) |>
  summarise(cite_ratio = mean(cite_ratio)) |>
  mutate(cite_ratio = round(cite_ratio, 2)) |>
  left_join(
    select(
      philo_bib,
      old = id,
      displayauth,
      year,
      title
    ), by = "old"
  ) |>
  arrange(-cite_ratio) |>
  slice(1:50) |>
  mutate(Article = paste0(
    "@",
    str_replace_all(old,":","")
  )) |>
  mutate(Rank = row_number()) |>
  select(Rank,
         Article,
         Ratio = cite_ratio)

avail_2021_cites_data <- citation_tibble |>
  filter(new_year >= 2021,
         new_year <= 2021) |>
  group_by(old, new_year) |>
  tally(name = "citations") |>
  ungroup() |>
  complete(old, new_year,
           fill = list(citations = 0),
           explicit = FALSE) |>
  group_by(new_year) |>
  mutate(all_cite = sum(citations)) |>
  ungroup() |>
  left_join(
    select(
      articles_per_year,
      new_year = old_year,
      available
    ), by = "new_year"
  ) |>
  mutate(cite_ratio = citations * available /all_cite) |>
  group_by(old) |>
  summarise(cite_ratio = mean(cite_ratio)) |>
  mutate(cite_ratio = round(cite_ratio, 2)) |>
  left_join(
    select(
      philo_bib,
      old = id,
      displayauth,
      year,
      title
    ), by = "old"
  ) |>
  arrange(-cite_ratio) |>
  slice(1:50) |>
  mutate(Article = paste0(
    "@",
    str_replace_all(old,":","")
  )) |>
  mutate(Rank = row_number()) |>
  select(Rank,
         Article,
         Ratio = cite_ratio)

avail_90s_cites_kable <- avail_90s_cites_data |>
  slice(1:10)

avail_2021_cites_kable <- avail_2021_cites_data |>
  slice(1:6) |>
  add_row(
    Rank = NA,
    Article = "...",
    Ratio = NA
  ) |>
  add_row(
    avail_2021_cites_data |>
      slice(12)
  ) |>
  add_row(
    Rank = NA,
    Article = "...",
    Ratio = NA
  ) |>
  add_row(
    avail_2021_cites_data |>
      slice(35)
  )

kable(avail_90s_cites_kable)
kable(avail_2021_cites_kable)

```

None of the pairwise comparisons here seem obviously absurd. Was "To be F is to be G" more influential in 2021 than "Causation" was in the 1990s? I wouldn't have thought so, but it's not as clear as in the previous set of comparisons. But it is clear that the numbers in the second table in @tbl-comp-cite-ratio are considerably higher than the first table, especially at the very top end. That suggests that the intuition that including so many articles from long ago in the comparison class was a mistake, and it has systematically increased the measure we're using for later years in implausible ways.

So what I've settled on is using the ratio of how often this article is cited in a year, to how often a _typical_ article is cited that year. By 'typical' I mean an article three to ten years old; as we'll see in @sec-age, those are the typical ages of cited articles. That deals with the intuitive problems of the previous measures, and it gets the results roughly right. In @tbl-comp-cite-ratio-typical, I'll do one last comparison between the 1990s and 2021 to make the point.

```{r}
#| label: tbl-comp-cite-ratio-typical
#| tbl-cap: "Most cited articles in the 1990s compared to typical citations, and in 2021."
#| tbl-subcap: 
#|   - "1990s"
#|   - "2021"
#| layout-ncol: 1

typical_90s_cites_data <- citation_tibble |>
  filter(new_year >= 1990,
         new_year <= 1999) |>
  group_by(old, new_year) |>
  tally(name = "citations") |>
  ungroup() |>
  complete(old, new_year,
           fill = list(citations = 0),
           explicit = FALSE) |>
  left_join(
    select(
      typical_citation_rate_per_year,
      new_year,
      mean_cites),
    by = "new_year") |>
  mutate(cite_ratio = citations / mean_cites) |>
  arrange(-cite_ratio) |>
  group_by(old) |>
  summarise(cite_ratio = mean(cite_ratio)) |>
  mutate(cite_ratio = round(cite_ratio, 2)) |>
  left_join(
    select(
      philo_bib,
      old = id,
      displayauth,
      year,
      title
    ), by = "old"
  ) |>
  arrange(-cite_ratio) |>
  slice(1:50) |>
  mutate(Article = paste0(
    "@",
    str_replace_all(old,":","")
  )) |>
  mutate(Rank = row_number()) |>
  select(Rank,
         Article,
         Ratio = cite_ratio)

typical_2021_cites_data <- citation_tibble |>
  filter(new_year >= 2021,
         new_year <= 2021) |>
  group_by(old, new_year) |>
  tally(name = "citations") |>
  ungroup() |>
  complete(old, new_year,
           fill = list(citations = 0),
           explicit = FALSE) |>
  left_join(
    select(
      typical_citation_rate_per_year,
      new_year,
      mean_cites),
    by = "new_year") |>
  mutate(cite_ratio = citations / mean_cites) |>
  group_by(old) |>
  summarise(cite_ratio = mean(cite_ratio)) |>
  mutate(cite_ratio = round(cite_ratio, 2)) |>
  left_join(
    select(
      philo_bib,
      old = id,
      displayauth,
      year,
      title
    ), by = "old"
  ) |>
  arrange(-cite_ratio) |>
  slice(1:50) |>
  mutate(Article = paste0(
    "@",
    str_replace_all(old,":","")
  )) |>
  mutate(Rank = row_number()) |>
  select(Rank,
         Article,
         Ratio = cite_ratio)

typical_90s_cites_kable <- typical_90s_cites_data |>
  slice(1:10)

typical_2021_cites_kable <- typical_2021_cites_data |>
  slice(1:10)

kable(typical_90s_cites_kable)
kable(typical_2021_cites_kable)
```

The numbers in the second table are a little higher, but not overly so. In any case, one would expect the top end of a scale like this to be higher when just looking at a single year, where there is more variation, than at an average over a decade.^[If I did the same comparison year-by-year, there are individual years where "Meaning" [@WOSA1957CGZ6000005], "Justice as Fairness: Political not Metaphysical" [@WOSA1985APA8500001] and "Concepts of Supervenience" [@WOSA1984TV24600001] have a higher ratio of citations to the average typical article than "New Work" does in 2021.] So I'll take this as the measure of age-adjusted number of citations. That is, to factor out the age effect on citations, I'll divide the number of citations an article receives in a year by the average number that a typical, i.e., 3-10 year old, article receives that year.

<!--


# Methodology {#sec-methodology}

As noted above, the study here is based on the Web of Science database, which my institution makes available with a subscription. That is, it lets members of the institution download the full database for research purposes. This is a rather large collection of files; after de-compression they come to over a terabyte. I selected records that were marked as _articles_ (as opposed to discussion notes, book reviews, editorial matters, and so on), and whose category was either Philosophy or History & Philosophy of Science. I then selected by hand the hundred journals with the most entries which were (a) primarily English language, (b) not primarily history of science and (c) broadly 'analytic' rather than 'continental'. These were somewhat subjective choices, but the result was a reasonable collection of the journals which are most important for telling the story of a certain kind of philosophy over the last several decades. The list of journals, as well as the dates covered by the index, is shown in @tbl-list-of-journals.

```{r}
#| label: tbl-list-of-journals
#| tbl-cap: "The journals included in this study."

require(knitr)
temp <- active_philo_bib |>
  filter(year >= start_year, year <= end_year) |>
  filter(id != "gettier1963") |>
  group_by(journal) |> 
  summarise(Articles = n(), `First Year` = min(year), `Most Recent Year` = max(year)) |>
  rename(Journal = journal)
kable(temp)
```

The column 'First Year' is *not* the first year the journal published; it is the first year that Web of Science indexed the journal. This often makes a difference; because _Analysis_ isn't indexed before 1975, we don't get "Is Knowledge Justified True Belief?" [@Gettier1963], or much of the initial literature it generated. Still, we do have a lot of information to work with, as long as we're careful about the limitations. Similarly, the column 'Last Year' is not the last year the journal was published; thankfully most of these journals are still in operation. It's not even the last year that Web of Science has records for. For most of the journals, there were records for 2022, and even occasional records for 2023. But I stopped the study in 2021 because it was the last year we had something that felt close enough to a full year's data. 

The database is supposed to tell you, for each indexed article, which things it cites. The reliability of this is mixed, especially with citations that are in footnotes rather than in a bibliography. And the data needs a huge amount of cleaning. Eugenio @Petrovich2024 did a similar study to this one focussing on five high profile journals, and his first step was a rather extensive bit of data cleaning.^[See section 4.2.4 of his book for more details on the challenges he faced.]

That said, for one important class of citations the data seems fairly reliable (at least as far as I could check), and not in need of much cleaning. When the citation is to another article that Web of Science indexes, the database includes the internal reference number of the cited article. By simply filtering for references that have an internal reference of this kind, we can quickly get a fairly accurate record of when the articles in @tbl-list-of-journals cite other articles on the table.

The upside of this approach, as opposed to the more thorough approach that Petrovich used, is that it makes it practical to study a hundred journals over sixty years. The downside is that it means we don't see citations to anything other than journal articles, and articles in these journals in particular. Obviously a full study of the citations in philosophy journals would want to pay some attention to citations of _Philosophical Investigations_, _A Theory of Justice_, _On the Plurality of Worlds_, and many many other books. This is not that 'full study'. Instead it's an attempt to analyse an important part of the citation data; a part that happens to be much easier to access.

So for the most part the method used here is that I downloaded hundreds of XML files from Web of Science and ran some filters on them. This took a few hours  even modern computers struggle to analyse a terabyte's worth of information quickly  but it wasn't that sophisticated. There were only two other things I had to do to fix the data.

The way Web of Science handles the 'supplements' to _Nos_, i.e., _Philosophical Perspectives_ and _Philosophical Issues_, was a little uneven. Some years these are recorded as being their own thing, i.e., with a source name of _Philosophical Perspectives_ or _Philosophical Issues_; and some years they are recorded as special issues of _Nos_. When they were listed as special issues, the citations were extremely unreliable. Some high profile articles are recorded as having no citations until several years after publication. The bibliographic information for the articles themselves was also spotty. So I've manually removed all records that were listed as special or supplementary issues of _Nos_ (and similarly removed the citations to those article that did get tracked).

The other big problem is that for several journals, 1974 is missing from the index. In a couple of cases, 1973 is also missing. And in one very important case, 1971 and 1972 are missing as well. That 'important case' is _The Journal of Philosophy_. Between 1971 and 1974 it published groundbreaking articles by Harry @Frankfurt1971, George @Boolos1971, Paul @Benacerraf1973, Jaegwon @Kim1973, Michael @Friedman1974, Isaac @Levi1974, and David Lewis [-@Lewis1971cen; -@Lewis1973ben]. This seemed like a break in the data that needed fixing if I was going to tell the story correctly. So I used JSTOR to find a full list of articles (as opposed to notes or book reviews) in _Journal of Philosophy_ in those years, and then looked through the citations in articles in @tbl-list-of-journals to see which citations were to one of those articles. This did mean I was using a different classification of publications into articles and non-articles, and there are some odd choices.^[Notably, the JSTOR list seemed to exclude the symposium centered around Kenneth Arrow's "Some Ordinalist-Utilitarian Notes on Rawlss Theory of Justice"; I'm not sure why that was.] And it meant I had to do a fair bit of data cleaning just to track down references to those four years.^[A non-trivial chunk of the cleaning was sorting through the many and varied ways that philosophers have spelled Brian O'Shaughnessy's name over the years.] While I've strived to make the data as consistent as possible with the other years, it's possible that I haven't succeeded, and some discontinuities around the early 1970s are due to this discontinuity in how the data was acquired.

After all that, we are left with `{r} nrow(article_years)` articles, from "Aristotle and the Sea Battle" [@Anscombe1956] to "Zooming Irresponsibly Down the Slippery Slope" [@Coren2021]. These articles collectively cite each other `{r} nrow(citation_tibble)` times.

# Period Effects {#sec-period}

Those  `{r} nrow(citation_tibble)` citations are not distributed evenly over time. Instead, they grow rapidly. At the start, in 1956, there are only `{r} filter(all_citations_per_year, new_year == 1956)$citations` citations. That's not too surprising; without the ability to cite preprints, there aren't going to be many citations of articles that have come out that year. By 2021, there are `{r} filter(all_citations_per_year, new_year == 2021)$citations`. In @fig-citationsperyear, I show how these grew; the striking thing to me is the big jump between 2020 and 2021.

```{r}
#| label: fig-citationsperyear-draft
#| fig-cap: "The number of citations in the dataset made each year."

all_citations_per_year_plot
```

What explains this dramatic growth? Part of the explanation is that more articles are being published, and more articles are being indexed. @fig-articlesperyear shows how many articles are in the dataset each year.

```{r}
#| label: fig-articlesperyear-draft
#| fig-cap: "The number of articles in the dataset published each year."

articles_per_year_plot
```

That explains some of the growth, but not all of it. The curve in @fig-articlesperyear is not nearly as steep as the curve in @fig-citationsperyear. The number of (indexed) citations per article is also rising. In @fig-outboundcitations I've plotted the average number of citations to other articles in the dataset each year.

```{r}
#| label: fig-outboundcitations-draft
#| fig-cap: "The average number of citations to indexed articles each year."

outbound_citations_plot
```

There are a few possible explanations for the shape of this graph.

At the left-hand edge, there are obvious boundary effects. Since we're only counting citations to articles published since 1956, it isn't surprising that there aren't very many of them per article in the 1950s. Since articles rarely get unpublished, there are more articles available to cite every year.

The next three explanations are a bit more speculative, and I've put them in increasing order of speculativeness.

First, the most casual perusal of philosophy journals over time will tell you that the number of citations is increasing. It is now commonplace to have bibliographies several pages long. This was considerably less common a few decades ago. There are more citations to indexed philosophy journals in part because there are more citations.

Second, it feels like the relative importance of _journals_, as opposed to books or edited volumes, in journal articles is growing. This study can't verify that, since I filtered out all citations to things other than journals. But the same kind of casual perusal that tells you three page bibliographies are more common than they used to be, also suggests that a greater percentage of those bibliographies consists of other journals.

There is a third factor I'd like to study, but again this dataset won't help much with it. Antecedently, I'd have guessed that the rate of citation of _non_-philosophy journals was increasing. In particular, philosophers seem to spend a lot more time discussing results in psychology now than they used to do. If that were true, it would encourage generate a downwards slope in @fig-outboundcitations, which obviously isn't what we see at the end. But maybe the rate of citations to all journals is growing even more rapidly than the rate of citations to philosophy journals. That will be left as a study for another day.

Although the number of citations is going up, the number of articles available to be cited is also going up. Say an article is _available_ if it is published in a year iff it is published in or before that year. That's not quite right in either direction; some articles are cited before publication, some articles that come out in December aren't in any real sense available to be cited in January. But it's close enough. Say an article is from a year that is _typically_ cited iff it is between 3 and 10 years before the citing year. This notion will play a big role in @sec-age; I'm going to use these as a way of getting something like a base rate for citations in a given year. Using these definitions, @fig-articlecounts shows how many articles are available to be cited each year, and are from years that are typically cited.

```{r}
#| label: fig-articlecounts-draft
#| column: screen-inset
#| fig-cap: "Article counts."
#| fig-subcap: 
#|   - "Available articles"
#|   - "Typically cited articles"
#| layout-ncol: 2
#| fig-column: screen-inset

available_plot
typical_plot
```

In @fig-citationcounts, I've shown how often, in each year, the available articles, and the 'typical' articles are cited. The 'available' graph is obviously similar to @fig-citationsperyear; under 1% of citations are to articles published in future years. One thing that will be useful in @sec-age is that the graphs in @fig-citationcounts have a similar shape.

```{r}
#| label: fig-citationcounts-draft
#| column: screen-inset
#| fig-cap: "Citation counts."
#| fig-subcap: 
#|   - "Citations to available articles"
#|   - "Citations to typical articles"
#| layout-ncol: 2
#| fig-column: screen-inset

available_citations_per_year_plot 
typical_citations_per_year_plot
```

Putting all these together we can work out how often, on average, available articles, and typical articles, are cited in each year. The results are in @fig-citationrate.

```{r}
#| label: fig-citationrate-draft
#| column: screen-inset
#| fig-cap: "Mean annual citations to different article kinds."
#| fig-subcap: 
#|   - "Available articles"
#|   - "Typical articles"
#| layout-ncol: 2


available_citation_rate_per_year_plot 
typical_citation_rate_per_year_plot 

```

Three things stand out about @fig-citationrate. One is that the two graphs have pretty similar shapes. Using citations from 3 to 10 years prior to the citing year is a pretty good proxy for all citations, and it turns out to be stable in other ways. A second is that both graphs are fairly flat for a long time. Between the mid 1970s and early 2000s they bounce around without moving much. Then they take off, and go through the roof in 2021. The other thing is that these are low numbers. For most of this study, an arbitrary article in one of these hundred journals was cited in one of those journals once a _decade_. Actually, since citation rates are extremely long-tailed, and mean rates are well above medians, that somewhat overstates how often the 'average article' was being cited. Frequent citation is very much not the norm.^[In the long run the average number of times an article is cited equals the average number of citations per article. So it shouldn't be too surprising that most article have just a handful of citations in philosophy journals.]

The various period effects are substantial; to get an reliable picture of the trends in citation patterns, we're going to have to allow for them.

# Age Effects {#sec-age}

The size of the period effects would suggest that we can't work out age effects by simply taking averages over the whole dataset. Surprisingly, if we do use the simplest possible method of working out age effects, we get roughly the right result.

Let's start with that simplest possible method. Say the _age_ of a citation is the time in years between the publication date of the citing article, and the publication date of the cited article. Then we can calculate the number of citations with each possible age. The result of that is shown in @fig-rawage.

```{r}
#| label: fig-rawage
#| fig-cap: "The age distribution of citations in the dataset."

raw_age_plot
```

The picture in @fig-rawage is fairly intuitive. Articles rarely get cited before they are published.^[Though in "Naive Validity, Internalization, and Substructural Approaches To Paradox" [@Rosenblatt2017], there are three citations to then forthcoming papers in Synthese which eventually appeared in 2021, giving them an age of -4.] Then they take a little bit of time to get noticed, before hitting their peak citations between 2 and 5 years after publication. After that it's a rapid, and then a slow, decline. For the classic articles, citations never really stop; @Anscombe1956 is cited by @Izgin2020. But most articles reach the end of their citation life sooner or, occasionally, later.

But the fact that @fig-rawage looks plausible shouldn't obscure the fact that this is a lousy methodology. Given how many of the citations are in the last few years, what this graph tells us is largely what citation practices with respect to age have been like in recent times. It could be that the overall picture is very different, once we look closely.

As it turns out though, this is roughly the right picture. I'll show that with some graphs that are a bit more careful about adjusting for the period effect.

The key notion is what I'm going to call the *citation ratio*. This is a function that takes two years, which I'll call _old_ and _new_, as input. Intuitively, it measures how often articles from _old_ are cited in _new_, normalised for how many articles are published in _old_, and what the citation practices are in _new_. More formally, it is the following ratio:

- The numerator is how often the average article in _old_ is cited in _new_. So we search the articles published in _new_, count up the number of citations of articles published in _old_, and divide by the number of articles published in _old_.
- The denominator is the rate a 'typical' article is cited in _new_. Remember that I'm defining, somewhat stipulatively, a typical article to be published between `{r} typical_low` and `{r} typical_high` years before _new_. So again we search the articles published in _new_, count the citations to articles published `{r} typical_low` to `{r} typical_high` years earlier, and divide by the number of articles originally published `{r} typical_low` to `{r} typical_high` years earlier.

```{r}
#| label: paramsforratioexample

#sample_old <- 1991
#sample_new <- 1998
sample_old <- 1985
sample_new <- 1997

num_of_num <- nrow(filter(citation_tibble, old_year == sample_old, new_year == sample_new))
den_of_num <- nrow(filter(active_philo_bib, year == sample_old))
num_of_den <- nrow(filter(citation_tibble, old_year >= sample_new - typical_high, old_year <= sample_new - typical_low, new_year == sample_new))
den_of_den <- nrow(filter(active_philo_bib, year >= sample_new - typical_high, year <= sample_new - typical_low))
num_of_cite <- num_of_num / den_of_num
den_of_cite <- num_of_den / den_of_den
overall_cite <- num_of_cite / den_of_cite
```

Let's illustrate this with an example, using `{r} sample_old` as _old_ and `{r} sample_new` as _new_. In `{r} sample_new`, indexed articles from `{r} sample_old` were cited `{r} num_of_num` times. There are `{r} den_of_num` articles published in `{r} sample_old` in the index, so the numerator for the citation ratio is `{r} num_of_num` / `{r} den_of_num`, i.e., about `{r} round(num_of_cite, 3)`. In the `{r} typical_low` to `{r} typical_high` years before `{r} sample_old`, there were `{r} den_of_den` indexed articles published. Those articles were, collectively, cited `{r} num_of_den` times in `{r} sample_new`. So the denominator, the average number of citations the typical article got in `{r} sample_new`, is `{r} num_of_den` / `{r} den_of_den`, i.e., about `{r} round(den_of_cite, 3)`. Putting those together, the citation ratio for `{r} sample_old` in `{r} sample_new` is (about) `{r} round(overall_cite,3)`. 

In @fig-ageeffecttibble I've graphed this citation ratio for many pairs of years. In the graph, the individual graphs (the _facets_), are for each value of _old_, the x-axis is the value for _new_, and the y-axis is the citation ratio. Note that before `{r} start_year + typical_high`, we can't calculate the citation ratio because there isn't enough data to calculate the typical citation rate. So the y-axis starts at `{r} start_year + typical_high`. And for most years there are no dots on the left side of the graph, because I haven't calculated the citation ratio in years where _old_ is later than _new_; there are few enough of these cases that they are best left out.

```{r}
#| label: fig-ageeffecttibble
#| fig-cap: "Each facet shows the relative citation rate for articles published that year at different ages."
#| fig-column: screen-inset

age_effect_tibble_plot +
    theme(
        axis.text = element_text(family = "Scala Sans Pro", size = 8),
        axis.title = element_text(family = "Scala Sans Pro", size = 5),
        strip.text.x = element_text(family = "Scala Sans Pro", size = 8, margin = margin(0,0,0,0, "cm"))
    )
```

There are several notable things about @fig-ageeffecttibble. The most important is that after some weird results in the early years, probably due to the small sample sizes, the graphs for each year look remarkably similar. The citation ratio takes a year or two to take off from zero, gets to its peak within two to four years after publication, and then declines. In earlier years, the rise and the fall are more rapid than in later years. This is actually a surprising result, and I'll come back in @sec-culture to why it might be. Still, it doesn't change that the shape of the curves is common enough to talk sensibly about an average curve. In @fig-ageeffecteverything, I've put most of the data from @fig-ageeffecttibble, with the x-axis now being age not the citing year, and the line showing the mean citation ratio by age. I say 'most' of the data because I didn't show the points for original publication years before 1975, where as you can see in the earlier graph, the data are much noisier with much smaller samples. But those years are used in the calculation of the average that's displayed.^[The graph also includes some 'jitter' to make the different points more easily visible. I've put each year of original publication in a different colour, with nearby years being in similar colours. But there are too many colours there to detect individual years, and we'll return to faceted graphs like @fig-ageeffecttibble when I want to highlight individual years.]

```{r}
#| label: fig-ageeffecteverything
#| fig-cap: "Age effects from 1970 onwards on a single graph, with the overall averrage shown."

age_effect_everything_plot
```

The mean curve in @fig-ageeffecteverything is really similar to the unadjusted age curve in @fig-rawage. This is what I meant earlier by saying that after a lot of calculations, we'd get back to the same aging curve that we got from the simplest possibe measure.

The calculations did have one really notable effect though. The unadjusted age numbers give us a sensible aging curve overall, but they give us an absurd aging curve for individual years. For most years in the dataset, the year they are most cited is not two to five years after initial publication; it is 2021. The point of the various adjustments in this section has been to make better sense of what's happening in individual years. 

The result is the striking lack of outliers in @fig-ageeffecteverything. All the individual data points are fairly close to the mean. There is some deviation, and there would be much more if I included the earlier years where the data is much noisier. The deviation there is will be the focus of much of the rest of this paper. Still, it's notable how consistent the age curve is, once we use citation ratio to account for period effects.

To end this section, I wanted to highlight two features of @fig-ageeffecttibble that are a little hard to see in the big graph. In @fig-peakratio, I've graphed the maximum value the citation ratio reaches for each year of initial publication. This is a bit misleading before `{r} start_year + typical_high`, because I don't have enough data to calculate citation ratios when the citing year is earlier than that, so it might have left off what would have been the high point. But from then on it's useful.

```{r}
#| label: fig-peakratio
#| fig-cap: "The maximum citation ratio in each facet in @fig-ageeffecttibble."

max_ratio_finder
```

After the initial jump upwards, and the very high numbers in the mid-1960s, the trend is a decline. In @fig-peakratiotime I've graphed out which age those peaks are hit at, for different years of initial publication starting in `{r} start_year + typical_high - 2`. 

```{r}
#| label: fig-peakratiotime
#| fig-cap: "For each original publication year, the age it hits maximum citation ratio."

age_at_max_ratio_plot
```

In @fig-peakratiotime, the graph is going slightly upwards. Putting these last two figures together, we get the claim I was gesturing at earlier: citation curves are getting flatter. The peaks are coming later, and they are lower.

# Cohort Effects {#sec-cohort}

So far we've seen how period effects and age effects between them can explain a lot of the trends we see in citation patterns. But there are systematic deviations from those patterns which remain. In @fig-fourdeviations, I've shown some of these. Each graph shows the citation ratio for articles published in a particular year, as compared to the average citation ratio at different ages.

```{r}
#| label: fig-fourdeviations
#| column: screen-inset
#| fig-cap: "Mean annual citations to different article kinds."
#| fig-subcap: 
#|   - "1961"
#|   - "1979"
#|   - "1985"
#|   - "2007"
#| layout-ncol: 2

year_to_mean_plot(1961)
year_to_mean_plot(1979)
year_to_mean_plot(1985)
year_to_mean_plot(2007)
```

In 1961 and 1985, the yearly values are predominantly below the mean line. In 1979 and 2007, they are predominantly above it, though this isn't true for the first few years of the 2007 data. Note that the graphs have different lengths. Everything stops in `{r} end_year`. And the 1961 data is cut off a little on the left because we only start calculating citation ratios in `{r} start_year + typical_high`. That's why the line showing the mean is differently shaped that year.

For each of year of original publication, we can calculate the mean difference between the citation ratio for that year, and the mean citation ratio for articles that age. That tells us how often articles published that year are cited, compared to how often you'd expect them to be cited knowing just the age and period effects. The results are in @fig-cohort.

```{r}
#| label: fig-cohort
#| fig-cap: "Cohort effects for different publication years."

year_by_year_average_plot
```

A couple of quick technical notes on @fig-cohort. I've added a smoothed curve over the graph to help make some of the features of it stand out. And in calculating the mean, I only included years where we had at least five years worth of data to calculate the mean age effect. So that means I haven't included what happens to `{r} start_year` papers when they are cited after `{r} end_year - min_data`. There isn't nearly enough data to say what one would 'expect' the usual aging curve to be at those points.




# Technical Explanations {#sec-technical}

# Cultural Explanations {#sec-culture}

# Substantive Explanations {#sec-substantive}

# Conclusion {#sec-conclusion}

-->