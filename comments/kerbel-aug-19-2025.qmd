---
title: "Two papers by Gabrielle Kerbel"
date: 19 August 2025
author: Brian Weatherson
bibliography: 
  - /Users/weath/Documents/quarto-articles/brian-quarto.bib
format:
  pdf:
    geometry: "left=1in,right=1in,top=1in,bottom=1in"
    mathfont: EB Garamond Math
    mainfont: EB Garamond Math
    sansfont: EB Garamond SemiBold
    mainfontoptions: 
      - ItalicFont=EB Garamond Italic
      - BoldFont=EB Garamond SemiBold
    fontsize: 12pt
    linkcolor: black
    urlcolor: black
    colorlinks: false
---

# Finding Truth-Directedness in the Guessing Framework

This looks to be in pretty good shape to me, and the main changes I'd make are cosmetic. That said, I had some ideas for what to change.

Page 2, third para
:    This will come up later, so it might be worth noting that the argument that the guessing framework endorses Matthew's judgments assumes the only guess on the table has as options *R* and ¬*R*.

Page 3, after inset
:    Saying they made true guesses seemed odd. They made guesses that were the true side of 0.5; is that all that's meant?

Page 3, last para
:    This is perhaps the biggest point. Having read the paper, I see why this isn't a problem. But when I read this I thought it was very odd to bring expectations in here. After all, we're meant to not be supposing that these credences are probabilities. And if they aren't, then expectations aren't even defined.    
    
    Now I take is that the expectations here are kind of objective. The point is not that either party has a higher expected accuracy rate given their own credences. That wouldn't be defined if they aren't probabilities, and would lead everyone to say that they are doing the best if it is defined. It's rather that given these (somewhat fictional) chance processes, and given the determined facts about rest stops, Susan on average does better than Matthew at a certain class of tasks.

    I'm not sure exactly what the right way to frame this should be. But maybe it's worth noting that the expectations here are not subjective. I don't have a great wording for that which isn't too clunky. I'd be kind of tempted to say that Susan does better than Matthew *on average* across a certain range of tasks, but maybe that's misleading in a different way.

    One other thing to note. Imagine that *R* is a proposition about a chance process, and it's common knowledge that the chance is 0.7. We still want to say that by accuracy standards, Susan does better on this question than Matthew. How do we say this on your view?

Page 7, last paragraph
:    It's not like any of the major views does well in the infinite case. Getting Jim's accuracy approach to say anything about finite vs countable additivity is not trivial.

Page 7, footnote 7
:    This is where my concern on page 3 really started to worry me. I get that you're not going to require these things, but the picture I had of your view from the intro made it sound like you would be caught in the same net as Sophie here.

Page 8, after heading
:    Should *P* be a **field** of propositions? I think strange things happen if it's an arbitrary set.

Page 9, last paragraph
:    This could be that I'm old, but I think saying that they should maximise expected accuracy is odd when the paper that started the whole accuracy approach, Jim's Non-Pragmatic Vindication, didn't give any role to expectations. And rightly so, since they aren't defined in some cases.

Page 17, last paragraph
:    What does it mean to say *R* and *S* are **independent**? Are they logically independent, causally independent, chance independent, credence independent? If the last, how is that defined if credences aren't probabilities? I think the term 'independent' is too polysemous to use without qualification.

Page 18, lines 2-3
:    These are very striking credence functions. They both assign credence greater than 0.5 to the true atom! I'm not sure that what we say about such weird cases will generalise further.

Page 19, third paragraph
:    Here's the start of something I felt a few times for the rest of the paper. There are some sweeping claims being made here that I'd like to see (a) made precise, and (b) proven.    
    
    Here are two things that seem not so clear to me. First, if Adrienne has credence greater than 0.5 in the true atom, there is some true information she can get which will make her have higher credence in some falsehood than some truth. Second, if *cr* starts with a higher credence in the truth than *cr*^\*^, then it is less vulnerable to malicious informing than *cr*^\*^. I'm not sure you really believe either of those things, but the text suggests both of them, and it would be good to be clearer about what you're claiming here.

Page 20, first inset
:    This feels like it should have a proof. Also, I'm not sure what *fewer* means here, given the possibility of infinite domains that you were worrying about earlier. (Same for *more* ways half way down the page.)

Page 22, inset
:    I don't know what uniformly closer to the truth means. Is it that for any true proposition, you have at least as high a credence, and for any false proposition, you have at most as high a credence? That's a really strong requirement, that is really only met in some edge-like cases.
    
    I also found the discussion of 'changing' in the next paragraph odd. This isn't a dynamic setting. Maybe stating more formally what DOMINANCE amounts to would resolve this.

# Dilating and Contracting Non-Arbitrarily

## Against Contraction

This felt like it needed a bit more. The big thing was that the argument in 3.1 felt really fast. I could sort of see (though only just) how it was an argument that arbitrary contractions would look bad from the perspective of the pre-contracting state. But that's not really using the guessing framework, and it's nothing like the argument that's given in section 3.2.

This matters because that's the really tough one. Being arbitrarily uncertain about whether grass is green seems a little odd. (Though Descartes might have views about that.) But it's just tough to say what's wrong with arbitrary contraction.

At a superficial level, it's odd that the argument about what looks like the hard case goes by so fast while you spend much longer on what looks like the easy case. More substantively, I think the contraction case needs to be linked more closely to the guessing framework for the paper to work.

## Against Contraction?

The background to all this is whether there is anything wrong with arbitrary contraction. The tonk like argument suggested that it is very very bad to allow both arbitrary dilation and arbitrary contraction. But it wasn't an argument against going in just one way.

Here's an argument that arbitrary contraction is fine. The point of credences is to guide guesses. When a person has imprecise credences, sometimes they have to guess arbitrarily. They should have a plan for how to do this, or they'll do dumb things. (It's bad to guess *q* when *p* is available, then guess *p* ∧ *r* when *q* is available, even if each individual guess might be licenced by something in the representor.) Once they have a plan, it's fine to adopt credences that make that plan the only permissible plan.

That's really quick, and I'm sure there are a million things wrong with it, but it's a better argument than can be given for arbitrary dilation, and it's worth having something to say about why arguments like it fail.

## Permissivism

One thing that feels like it is bubbling under the surface here is a connection to debates in epistemology/philosophy of science about permissivism and values. 

Start with a familiar case of inductive risk. Let's say we know *a* is *F*, and that 70% of *F*s are *G*s. We also know some extra things about *a*, but none of them are obviously relevant to being *G*. So let's say you conclude, permissibly, that there is no other relevant evidence, so we should just have credence 0.7 that *a* is *G*. But I'm an inductive wimp, and I think we don't know that none of these things are relevant quite yet. So my credence that *a* is *G* is [0.65, 0.75]. But after a bit more thought, I decide we do know that all the extra features of *a* are irrelevant, and come to have your credence as well.

This isn't quite an *arbitrary* contraction, but it is a contraction, and one that I think makes sense from the inside. Concluding that this really is a random, or representative, *F*, is the kind of thing that we need evidence for, and some people are more inductively cautious than others. But also, there's no one right answer here. Someone could decide that they didn't feel like being as cautious as they had been.

This comes up in RATMAX. Is this really a good rule? Why can't I change because I have become a bit more inductively risk-tolerant? That's not an accuracy increasing change; I don't actually know how to compare the accuracy of 0.7 and [0.65, 0.75]. But it feels like a reasonable, maybe rational, change.

## Smaller Points

Page 2, line 12
:    Is it that *cr* has a degree of confidence, or that the person with *cr* does?

Page 2, line 13
:    It wasn't clear what was being allowed in via the parenthetical. Is it non-probabilistic credence functions?

Page 2, line 16
:    I'm not sure what compatibility means here. Maybe this relates to the point about permissivism above.

Page 2, line 22
:    There are other ways to dilate and contract than that I'd say. Going from *cr*(*p*) in [0.2, 0.8] to it in [0.4, 0.6] is a contraction.

Page 2, line 31
:    This is reminiscent of Arthur Prior's *tonk* operator.

Page 2, line 32
:    The second argument is less compelling, especially if one is sympathetic to the kind of permissivism I was sketching above.
    
    By the way, if my response in -@Weatherson2015-WEAFBR to the immodesty argument that Gordon made in -@Belot2013 works, certain contractions can't be allowed. That's a very big *if* though.

Page 3, line 7
:    If there are multiple standards, couldn't one change which one was being used, and hence violate RATMAX.

Page 3, line 10
:    I don't get the 'and' in this heading. One version permits dilating; another permits contracting. No version was permitting arbitrary contraction **and** dilation.

Page 5, line 22
:    It's amusing to take the model to be that rational people are interested in *everything*.

Page 6, line 7
:    Introducing comparativism this far in seemed like a big thing to do. I also worry that it leads to a tension, though I'm not sure I understand the suggestion in 3.1, so I'm not sure exactly how it affects you. Anyway, assume that *p* has maximally imprecise credence, and *q* has precise credence 0.45. You now have to make a guess out of {*p*, ¬*p*, *q*}. Is it permissible to guess *q*? Here are two arguments. On the one hand, there is no *Pr* in the representor where *q* is maximal, so no. On the other hand, there is no alternative that you think *q* is less likely than, so yes. Comparativism, I think, pushes you to the second answer. But it's sort of in tension with the sets of credence functions approach.

Page 6, line 27
:    I mentioned above that I don't think this argument is connected enough to guessing, but I also don't understand it on its own merts. How can you abstain from guessing in these cases; I thought it was a forced choice?    
    
    Besides, does it even make sense to abstain. If the rule is that you get 1 point for a correct guess, and 0 points for abstain/incorrect guess, then abstain away.

    Also, in three way choices, abstaining might be a very bad idea. What if you have to guess between *p*, *q* and *r*, and in fact *p* and *q* are true while *r* is false, and you have high overlapping credences in *p*, *q*, while you have low credence in *r*. Abstaining seems very bad - you should just pick *p* or *q* arbitrarily.

Page 7, line 10
:    I didn't understand this paragraph. Do they dilate to a point where there is a function where *cr*(*J*) > *cr*(*S*)? That seems extreme. I think I just didn't follow what was going on.

Page 7, line 26
:    Using opportunity costs like this seems like the right way to go, though as I mentioned above, it gets messy when there are multiple options.

## Digression One: Negative Dominance

OK, the points from here on are just if you are bored/have too much time on your hands. They certainly aren't things to be done before this year's job market. They probably aren't things to be done before any job market and/or tenure. But maybe they'll be of interest down the track.

I thought the guessing framework had a way of stating something like the Negative Dominance principle that Harvey @Lederman2025 has been worried about. Here's how I'd state it for guessing. 

First, assume that we have some set of lottery propositions *L*~1~, ..., *L~n~*, which are exclusive, exhaustive, and known to be independent of everything else Guesser cares about. (Sort of like the chance propositions you use in _Finding Truth-Directedness_.) The following two games seem similar.

> **Game One**    
>    
> There are two sequences of propositions *P* = ⟨*p*~1~, ..., *p~n~*⟩, and Q = ⟨*q*~1~, ..., *q~n~*⟩. You have to guess either *P* or *Q*, and then we'll work out which *L~i~* is true, and if you guess *P*, you win if *p~i~* is true, while if you guess *Q*, you win if *q~i~* is true.

> **Game Two**    
>    
> Let *P* = ((*L*~1~ ∧ *p*~1~) ∨ … ∨ (*L~n~* ∧ *p~n~*)), while *Q* = ((*L*~1~ ∧ *q*~1~) ∨ … ∨ (*L~n~* ∧ *q~n~*)). You have to guess which of *P* and *Q* is true.

**Game Two** is exactly the kind of guessing game Sophie talks about, but it will make better sense of what Harvey has in mind to talk about **Game One**. But I think they're equivalent, so that's ok.

> **Negative Dominance (Guessing)**    
>    
> If in **Game One** you'd strictly prefer to guess *P* rather than *Q*, then there is some pair *p~i~*, *q~j~* such that given a choice of guessing between these two, you'd strictly prefer to guess *p~i~*.

As I understand it, the imprecise framework violates this. Let *u* be some maximally uncertain proposition, and let *c* be a chancy proposition with known chance 0.45. And let *L*~1~ and *L*~2~ each have chance 0.5; they are outcomes of a fair coin flip. Finally, let *P* be ⟨*u*, ¬*u*⟩, while *Q* is ⟨*c*, *c*⟩. That is, *Q* is just a guess on *c*. In every function in the representor, (*L*~1~ ∧ *u*) ∨ (*L*~2~ ∧ ¬*u*) has probability 0.5, so it's higher than *Q*, so it's the uniquely permissible guess. But neither *u* nor ¬*U* is uniquely permissible when the only other option is *c*.

As Harvey says, there is something odd about this. Why think that the lottery that *P* represents is strictly better than the lottery that *Q* represents when none of the prizes in *P* is strictly better than any of the prizes in *Q*? I think there are things to say here, but it's a good challenge. If you are doing a longer project on guessing and imprecise credence, it feels like something to maybe consider - but not right away!

There is a bit of literature on a principle stronger than what Harvey uses where we ask whether choosing *P* over *Q* in **Game One** requires that for some *p~i~* and *q~i~* (note same subscript) we should choose the *p~i~*. Harvey has these arguments that I'm not sure I follow that that's too strong a constraint, but his weaker one is not. The modern literature on this starts from a paper by Casper @hare2010take, and Miriam @schoenfield2014decision has an important role in it; perhaps she has worked on the connection between this and guessing.

(Very tenuous connection back to your paper: I kind of think the right way to respond to Harvey's arguments maybe might make arbitrary contraction more attractive. But I'm *really* unsure about that; I'm more sure Harvey's argument is interesting.)

## Digression Two: Guessing Functions

So I've been spending the spring and summer working through some stuff by Amartya Sen, especially his @Sen1970sec. And a big part of that book is the idea that we should at least supplement, and *maybe* replace, preference relations with choice functions. As he uses them, a choice function *C* takes a menu of options *O*, and returns a (non-empty) set of permissible alternatives from that menu.

Now this should sound a lot like the guessing game. We can imagine a function *G* that takes a menu of propositions *M*, and returns a set *P* of permissible guesses. The thing is, there is no reason to only consider the case where *M* is a pair-set. And it is a very interesting question whether *G* can/should be solely characterised by the values it takes when *M* is a pair-set. Over these two papers, I didn't see any examples where there were more than two options. But these cases are quite interesting.

One immediate benefit of doing things this way is that we get a quick characterisation of imprecision. Consider the following principle (roughly what Sen calls principle β).

> Assume that for some *M*, *G*(*M*) includes both *p* and *q*. Then for any *N* that includes both *p* and *q*, *p* is in *G*(*N*) iff *q* is.

Intuitively, this holds for precise representors, and fails for imprecise representors. Now one possibility (for future, future research) is whether the talk of representors could be dropped altogether, and we could just define precision/imprecision in terms of something like this principle. That's (sorta kinda) what Sen does for values.

This is more of a rabbit warren than a rabbit hole in terms of how many questions open up once you go this way. I might do something at EWIP later this term on some of this stuff. It all seems like it fits well with the guessing framework, but also isn't obviously relevant to *this* paper.

## Digression Three: Imprecision and Representors

This is all from memory, and I might be misremembering a key detail. But if I recall correctly, there is a different kind of argument against contraction in Walley's huge 1991 book. It goes something like this.

Walley was an arch-pragmatist. Every constraint was done in terms of Dutch Book/sure loss considerations. That was normal enough then, I guess a little less so now. For Walley, that includes countable Dutch Books. So he accepted countable additivity, because there is a countable Dutch Book against merely finitely additive credences.

So far, not so interesting. What he found, and here I'm really going from memory, was a set of merely finitely additive credence functions which, when taken as a representor, was not Dutch Bookable. And, this was the bizarre part, there was no way to represent it as a set of countably additive functions. I have no idea how this construction went (and I'm only 80% sure I'm recalling these properties correctly), but it led to some interesting claims.

This construction, I think, was a big part of why Walley didn't like the representor language. This state wasn't just a set of credence functions, because it was rational and it would be represented as a set of irrational functions. It would also be an argument against arbitrary contraction - after all contracting would take you to mere finite additivity.

Now I don't think it's worth getting into finite vs countable in this paper, and unless you have something that already works, probably not in anything you do at UM. That's really a down the line task. But there may be something here connecting contraction/dilation to countable/finite additivity.

## Digression Four: Linking the digressions up

So I have a quarter-baked idea for how to resolve some of the issues in the last three digressions, and in the process develop a possibly new theory. If I'd got your paper from a colleague, I'd suggest we work it up together. But since there is 0% chance that anything would come of this by the time the job market stuff is due (i.e., in a few weeks), and frankly only a slightly higher chance that anything would be ready for next year's job market, I think it would be a bad idea for you to work on it. Still, here's the idea in case you're interested.

As I've always understood Sophie's position, the metaphysics of precise/imprecise credences are meant to be taken care of before we get to guessing. We have these credences, determined somehow, and the guessing framework is a set of normative constraints on them. (That's how I've understood Jim's view more or less as well.) Idea: what if we flipped that around, and said the guessing framework was part of the metaphysical grounding of credences?

The idea is basically a generalisation of the comparativist framework. One kind of comparativist says (following roughly Ramsey), that having credence 2/3 in *p* just is having equal credence in *p* as in *q*~1~ ∨ *q*~2~, where *q*~1~, *q*~2~, and *q*~3~ are exclusive, exhaustive, and equal credence. That's a reduction of numerical credence to comparative credence, and I think it is plausible.

The guessing framework takes that further. What it is to have a certain imprecise credence just is to have some view about the permissibility of certain guesses. Just what that is might be tricky, and I really don't have the details. If we add in something like β as a coherence constraint on guesses, we get back to the standard comparativist framework. But if we don't add that in, we potentially get a very novel kind of imprecise view, that isn't committed to imprecise credences being sets of precise credences. If you pick the right constraints on guessing patterns, you can probably get around a lot of the puzzles I was just mentioning.

The upside of this is that no one has worked on this, and there are a lot of places where you have a free shot at a view no one has worked out. The downside is that the search space is huge, and when no one has worked on something, it sometimes happens that no one cares about the exploration. That's a really good reason for a grad student to not put too many resources into it. And of course it really might not work. (Also a good reason for someone who can see the job market to work on projects with a higher expected return.) But I suspect there's something novel here; it wasn't always true that imprecise credence just meant sets of credence functions, and maybe the guessing framework can open up new alternatives.

## References {-}